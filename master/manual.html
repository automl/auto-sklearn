<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Manual &#8212; AutoSklearn 0.14.6 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>

  </head><body>
  
  <a href="https://github.com/automl/auto-sklearn"
     class="visible-desktop hidden-xs"><img
    id="gh-banner"
    style="position: absolute; top: 50px; right: 0; border: 0;"
    src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
    alt="Fork me on GitHub"></a>
  <script>
    // Adjust banner height.
    $(function () {
      var navHeight = $(".navbar .container").css("height");
      $("#gh-banner").css("top", navHeight);
    });
  </script>


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          auto-sklearn</a>
        <span class="navbar-text navbar-version pull-left"><b>0.14.6</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Start</a></li>
                <li><a href="releases.html">Releases</a></li>
                <li><a href="installation.html">Installation</a></li>
                <li><a href="#">Manual</a></li>
                <li><a href="examples/index.html">Examples</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="extending.html">Extending</a></li>
                <li><a href="faq.html">FAQ</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Manual</a><ul>
<li><a class="reference internal" href="#resource-limits">Resource limits</a></li>
<li><a class="reference internal" href="#the-search-space">The search space</a></li>
<li><a class="reference internal" href="#model-selection">Model selection</a></li>
<li><a class="reference internal" href="#ensembling">Ensembling</a></li>
<li><a class="reference internal" href="#inspecting-the-results">Inspecting the results</a></li>
<li><a class="reference internal" href="#parallel-computation">Parallel computation</a></li>
<li><a class="reference internal" href="#other">Other</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <div class="section" id="manual">
<span id="id1"></span><h1>Manual<a class="headerlink" href="#manual" title="Permalink to this headline">¶</a></h1>
<p>This manual gives an overview of different aspects of <em>auto-sklearn</em>. For each section, we either references examples or
give short explanations (click the title to expand text), e.g.</p>
<details class="summary-b-code-examples-b">
<summary><b>Code examples</b></summary><p>We provide examples on using <em>auto-sklearn</em> for multiple use cases ranging from
simple classification to advanced uses such as feature importance, parallel runs
and customization. They can be found in the <a class="reference internal" href="examples/index.html#sphx-glr-examples"><span class="std std-ref">Examples</span></a>.</p>
</details><details class="summary-b-material-from-talks-and-presentations-b">
<summary><b>Material from talks and presentations</b></summary><p>We provide resources for talks, tutorials and presentations on <em>auto-sklearn</em> under <a class="reference external" href="https://github.com/automl/auto-sklearn-talks">auto-sklearn-talks</a></p>
</details><div class="section" id="resource-limits">
<span id="limits"></span><h2>Resource limits<a class="headerlink" href="#resource-limits" title="Permalink to this headline">¶</a></h2>
<p>A crucial feature of <em>auto-sklearn</em> is limiting the resources (memory and time) which the scikit-learn algorithms are
allowed to use. Especially for large datasets, on which algorithms can take several hours and make the machine swap,
it is important to stop the evaluations after some time in order to make progress in a reasonable amount of time.
Setting the resource limits is therefore a tradeoff between optimization time and the number of models that can be
tested.</p>
<details class="summary-b-time-and-memory-limits-b">
<summary><b>Time and memory limits</b></summary><p>While <em>auto-sklearn</em> alleviates manual hyperparameter tuning, the user still
has to set memory and time limits. For most datasets a memory limit of 3GB or
6GB as found on most modern computers is sufficient. For the time limits it
is harder to give clear guidelines. If possible, a good default is a total
time limit of one day, and a time limit of 30 minutes for a single run.</p>
<p>Further guidelines can be found in
<a class="reference external" href="https://github.com/automl/auto-sklearn/issues/142">auto-sklearn/issues/142</a>.</p>
</details><details class="summary-b-cpu-cores-b">
<summary><b>CPU cores</b></summary><p>By default, <em>auto-sklearn</em> uses <strong>one core</strong>. See also <a class="reference internal" href="#parallel"><span class="std std-ref">Parallel computation</span></a> on how to configure this.</p>
</details></div>
<div class="section" id="the-search-space">
<span id="space"></span><h2>The search space<a class="headerlink" href="#the-search-space" title="Permalink to this headline">¶</a></h2>
<p><em>Auto-sklearn</em> by default searches a large space to find a well performing configuration. However, it is also possible
to restrict the searchspace:</p>
<details class="summary-b-restricting-the-searchspace-b">
<summary><b>Restricting the searchspace</b></summary><p>The following shows an example of how to exclude all preprocessing methods and restrict the configuration space to
only random forests.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">autosklearn.classification</span>
<span class="n">automl</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">AutoSklearnClassifier</span><span class="p">(</span>
    <span class="n">include</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;classifier&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_forest&quot;</span><span class="p">],</span>
        <span class="s1">&#39;feature_preprocessor&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;no_preprocessing&quot;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="n">exclude</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
<span class="n">automl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">automl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Note:</strong> The strings used to identify estimators and preprocessors are the filenames without <em>.py</em>.</p>
<p>For a full list please have a look at the source code (in <cite>autosklearn/pipeline/components/</cite>):</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://github.com/automl/auto-sklearn/tree/master/autosklearn/pipeline/components/classification">Classifiers</a></p></li>
<li><p><a class="reference external" href="https://github.com/automl/auto-sklearn/tree/master/autosklearn/pipeline/components/regression">Regressors</a></p></li>
<li><p><a class="reference external" href="https://github.com/automl/auto-sklearn/tree/master/autosklearn/pipeline/components/feature_preprocessing">Preprocessors</a></p></li>
</ul>
</div></blockquote>
<p>We do also provide an example on how to restrict the classifiers to search over
<a class="reference internal" href="examples/40_advanced/example_interpretable_models.html#sphx-glr-examples-40-advanced-example-interpretable-models-py"><span class="std std-ref">Interpretable models</span></a>.</p>
</div></blockquote>
</details><details class="summary-b-turn-off-data-preprocessing-b">
<summary><b>Turn off data preprocessing</b></summary><p>Data preprocessing includes One-Hot encoding of categorical features, imputation
of missing values and the normalization of features or samples. These ensure that
the data the gets to the sklearn models is well formed and can be used for
training models.</p>
<p>While this is necessary in general, if you’d like to disable this step, please
refer to this <a class="reference internal" href="examples/80_extending/example_extending_data_preprocessor.html#sphx-glr-examples-80-extending-example-extending-data-preprocessor-py"><span class="std std-ref">example</span></a>.</p>
</details><details class="summary-b-turn-off-feature-preprocessing-b">
<summary><b>Turn off feature preprocessing</b></summary><p>Feature preprocessing is a single transformer which implements for example feature
selection or transformation of features into a different space (i.e. PCA).</p>
<p>This can be turned off by setting
<code class="docutils literal notranslate"><span class="pre">include={'feature_preprocessor'=[&quot;no_preprocessing&quot;]}</span></code> as shown in the example above.</p>
</details></div>
<div class="section" id="model-selection">
<span id="bestmodel"></span><h2>Model selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h2>
<p><em>Auto-sklearn</em> implements different strategies to identify the best performing model. For some use cases it might be
necessary to adapt the resampling strategy or define a custom metric:</p>
<details class="summary-b-use-different-resampling-strategies-b">
<summary><b>Use different resampling strategies</b></summary><p>Examples for using holdout and cross-validation can be found in <a class="reference internal" href="examples/40_advanced/example_resampling.html#sphx-glr-examples-40-advanced-example-resampling-py"><span class="std std-ref">example</span></a></p>
</details><details class="summary-b-use-a-custom-metric-b">
<summary><b>Use a custom metric</b></summary><p>Examples for using a custom metric can be found in <a class="reference internal" href="examples/40_advanced/example_metrics.html#sphx-glr-examples-40-advanced-example-metrics-py"><span class="std std-ref">example</span></a></p>
</details></div>
<div class="section" id="ensembling">
<span id="ensembles"></span><h2>Ensembling<a class="headerlink" href="#ensembling" title="Permalink to this headline">¶</a></h2>
<p>To get the best performance out of the evaluated models, <em>auto-sklearn</em> uses ensemble selection by <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/1015330.1015432">Caruana et al. (2004)</a>
to build an ensemble based on the models’ prediction for the validation set.</p>
<details class="summary-b-configure-the-ensemble-building-process-b">
<summary><b>Configure the ensemble building process</b></summary><p>The following hyperparameters control how the ensemble is constructed:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ensemble_size</span></code> determines the maximal size of the ensemble. If it is set to zero, no ensemble will be constructed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ensemble_nbest</span></code> allows the user to directly specify the number of models considered for the ensemble.  This hyperparameter can be an integer <em>n</em>, such that only the best <em>n</em> models are used in the final ensemble. If a float between 0.0 and 1.0 is provided, <code class="docutils literal notranslate"><span class="pre">ensemble_nbest</span></code> would be interpreted as a fraction suggesting the percentage of models to use in the ensemble building process (namely, if ensemble_nbest is a float, library pruning is implemented as described in <a class="reference external" href="https://dl.acm.org/doi/10.1109/ICDM.2006.76">Caruana et al. (2006)</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_models_on_disc</span></code> defines the maximum number of models that are kept on the disc, as a mechanism to control the amount of disc space consumed by <em>auto-sklearn</em>. Throughout the automl process, different individual models are optimized, and their predictions (and other metadata) is stored on disc. The user can set the upper bound on how many models are acceptable to keep on disc, yet this variable takes priority in the definition of the number of models used by the ensemble builder (that is, the minimum of <code class="docutils literal notranslate"><span class="pre">ensemble_size</span></code>, <code class="docutils literal notranslate"><span class="pre">ensemble_nbest</span></code> and <code class="docutils literal notranslate"><span class="pre">max_models_on_disc</span></code> determines the maximal amount of models used in the ensemble). If set to None, this feature is disabled.</p></li>
</ul>
</details><details class="summary-b-inspect-the-final-ensemble-b">
<summary><b>Inspect the final ensemble</b></summary><p>The results obtained from the final ensemble can be printed by calling <code class="docutils literal notranslate"><span class="pre">show_models()</span></code>.
The <em>auto-sklearn</em> ensemble is composed of scikit-learn models that can be inspected as exemplified
in the Example <a class="reference internal" href="examples/40_advanced/example_get_pipeline_components.html#sphx-glr-examples-40-advanced-example-get-pipeline-components-py"><span class="std std-ref">Obtain run information</span></a>.</p>
</details><details class="summary-b-fit-ensemble-post-hoc-b">
<summary><b>Fit ensemble post-hoc</b></summary><p>To use a single core only, it is possible to build ensembles post-hoc. An example on how to do this (first searching
for individual models, and then building an ensemble from them) can be seen in
<a class="reference internal" href="examples/60_search/example_sequential.html#sphx-glr-examples-60-search-example-sequential-py"><span class="std std-ref">Sequential Usage</span></a>.</p>
</details></div>
<div class="section" id="inspecting-the-results">
<span id="inspect"></span><h2>Inspecting the results<a class="headerlink" href="#inspecting-the-results" title="Permalink to this headline">¶</a></h2>
<p><em>auto-sklearn</em> allows users to inspect the training results and statistics. Assume we have a fitted estimator:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">autosklearn.classification</span>
<span class="n">automl</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">AutoSklearnClassifier</span><span class="p">()</span>
<span class="n">automl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p><em>auto-sklearn</em> offers the following ways to inspect the results</p>
<details class="summary-b-basic-statistics-b">
<summary><b>Basic statistics</b></summary><p><code class="docutils literal notranslate"><span class="pre">sprint_statistics()</span></code> is a method that prints the name of the  dataset, the metric used, and the best validation score
obtained by running <em>auto-sklearn</em>. It additionally prints the number of both successful and unsuccessful
algorithm runs.</p>
</details><details class="summary-b-performance-over-time-b">
<summary><b>Performance over Time</b></summary><p><code class="docutils literal notranslate"><span class="pre">performance_over_time_</span></code>  returns a DataFrame containing the models performance over time data, which can
be used for plotting directly (Here is an example: <a class="reference internal" href="examples/40_advanced/example_pandas_train_test.html#sphx-glr-examples-40-advanced-example-pandas-train-test-py"><span class="std std-ref">Performance-over-time plot</span></a>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">automl</span><span class="o">.</span><span class="n">performance_over_time_</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Timestamp&#39;</span><span class="p">,</span>
        <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span>
        <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Auto-sklearn accuracy over time&#39;</span><span class="p">,</span>
        <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</details><details class="summary-b-evaluated-models-b">
<summary><b>Evaluated models</b></summary><p>The results obtained from the final ensemble can be printed by calling <code class="docutils literal notranslate"><span class="pre">show_models()</span></code>.</p>
</details><details class="summary-b-leaderboard-b">
<summary><b>Leaderboard</b></summary><p><code class="docutils literal notranslate"><span class="pre">automl.leaderboard()</span></code> shows the ensemble members, check the <a class="reference internal" href="api.html#autosklearn.classification.AutoSklearnClassifier.leaderboard" title="autosklearn.classification.AutoSklearnClassifier.leaderboard"><code class="xref py py-meth docutils literal notranslate"><span class="pre">docs</span></code></a> for using leaderboard for getting information on <em>all</em> runs.</p>
</details><details class="summary-b-other-b">
<summary><b>Other</b></summary><p><code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> returns a dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.</p>
</details></div>
<div class="section" id="parallel-computation">
<span id="parallel"></span><h2>Parallel computation<a class="headerlink" href="#parallel-computation" title="Permalink to this headline">¶</a></h2>
<p>In it’s default mode, <em>auto-sklearn</em> uses <strong>one core</strong> and interleaves ensemble building with evaluating new
configurations.</p>
<details class="summary-b-parallelization-with-dask-b">
<summary><b>Parallelization with Dask</b></summary><p>Nevertheless, <em>auto-sklearn</em> also supports parallel Bayesian optimization via the use of
<a class="reference external" href="https://distributed.dask.org/">Dask.distributed</a>. By providing the arguments <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>
to the estimator construction, one can control the number of cores available to <em>auto-sklearn</em>
(As shown in the Example <a class="reference internal" href="examples/60_search/example_parallel_n_jobs.html#sphx-glr-examples-60-search-example-parallel-n-jobs-py"><span class="std std-ref">Parallel Usage  on a single machine</span></a>).
Distributed processes are also supported by providing a custom client object to <em>auto-sklearn</em> like
in the Example: <a class="reference internal" href="examples/60_search/example_parallel_manual_spawning_cli.html#sphx-glr-examples-60-search-example-parallel-manual-spawning-cli-py"><span class="std std-ref">Parallel Usage: Spawning workers from the command line</span></a>. When
multiple cores are
available, <em>auto-sklearn</em> will create a worker per core, and use the available workers to both search
for better machine learning models as well as building an ensemble with them until the time resource
is exhausted.</p>
<p><strong>Note:</strong> <em>auto-sklearn</em> requires all workers to have access to a shared file system for storing training data and models.</p>
<p><em>auto-sklearn</em> employs <a class="reference external" href="https://github.com/joblib/threadpoolctl/">threadpoolctl</a> to control the number of threads employed by scientific libraries like numpy or scikit-learn. This is done exclusively during the building procedure of models, not during inference. In particular, <em>auto-sklearn</em> allows each pipeline to use at most 1 thread during training. At predicting and scoring time this limitation is not enforced by <em>auto-sklearn</em>. You can control the number of resources
employed by the pipelines by setting the following variables in your environment, prior to running <em>auto-sklearn</em>:</p>
<div class="highlight-shell-session notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span> <span class="nv">OPENBLAS_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
<span class="gp">$ </span><span class="nb">export</span> <span class="nv">MKL_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
<span class="gp">$ </span><span class="nb">export</span> <span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
<p>For further information about how scikit-learn handles multiprocessing, please check the <a class="reference external" href="https://scikit-learn.org/stable/computing/parallelism.html">Parallelism, resource management, and configuration</a> documentation from the library.</p>
</details></div>
<div class="section" id="other">
<span id="othermanual"></span><h2>Other<a class="headerlink" href="#other" title="Permalink to this headline">¶</a></h2>
<details class="summary-b-supported-input-types-b">
<summary><b>Supported input types</b></summary><p><em>auto-sklearn</em> can accept targets for the following tasks (more details on <a class="reference external" href="https://scikit-learn.org/stable/modules/multiclass.html">Sklearn algorithms</a>):</p>
<ul class="simple">
<li><p>Binary Classification</p></li>
<li><p>Multiclass Classification</p></li>
<li><p>Multilabel Classification</p></li>
<li><p>Regression</p></li>
<li><p>Multioutput Regression</p></li>
</ul>
<p>You can provide feature and target training pairs (X_train/y_train) to <em>auto-sklearn</em> to fit an
ensemble of pipelines as described in the next section. This X_train/y_train dataset must belong
to one of the supported formats: np.ndarray, pd.DataFrame, scipy.sparse.csr_matrix and python lists.
Optionally, you can measure the ability of this fitted model to generalize to unseen data by
providing an optional testing pair (X_test/Y_test). For further details, please refer to the
Example <a class="reference internal" href="examples/40_advanced/example_pandas_train_test.html#sphx-glr-examples-40-advanced-example-pandas-train-test-py"><span class="std std-ref">Performance-over-time plot</span></a>.
Supported formats for these training and testing pairs are: np.ndarray,
pd.DataFrame, scipy.sparse.csr_matrix and python lists.</p>
<p>If your data contains categorical values (in the features or targets), autosklearn will automatically encode your
data using a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">sklearn.preprocessing.LabelEncoder</a>
for unidimensional data and a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html">sklearn.preprocessing.OrdinalEncoder</a>
for multidimensional data.</p>
<p>Regarding the features, there are two methods to guide <em>auto-sklearn</em> to properly encode categorical columns:</p>
<ul class="simple">
<li><p>Providing a X_train/X_test numpy array with the optional flag feat_type. For further details, you
can check the Example <a class="reference internal" href="examples/40_advanced/example_feature_types.html#sphx-glr-examples-40-advanced-example-feature-types-py"><span class="std std-ref">Feature Types</span></a>.</p></li>
<li><p>You can provide a pandas DataFrame, with properly formatted columns. If a column has numerical
dtype, <em>auto-sklearn</em> will not encode it and it will be passed directly to scikit-learn. If the
column has a categorical/boolean class, it will be encoded. If the column is of any other type
(Object or Timeseries), an error will be raised. For further details on how to properly encode
your data, you can check the Pandas Example
<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html">Working with categorical data</a>).
If you are working with time series, it is recommended that you follow this approach
<a class="reference external" href="https://stats.stackexchange.com/questions/311494/">Working with time data</a>.</p></li>
</ul>
<p>Regarding the targets (y_train/y_test), if the task involves a classification problem, such features will be
automatically encoded. It is recommended to provide both y_train and y_test during fit, so that a common encoding
is created between these splits (if only y_train is provided during fit, the categorical encoder will not be able
to handle new classes that are exclusive to y_test). If the task is regression, no encoding happens on the
targets.</p>
</details><details class="summary-b-model-persistence-b">
<summary><b>Model persistence</b></summary><p><em>auto-sklearn</em> is mostly a wrapper around scikit-learn. Therefore, it is
possible to follow the
<a class="reference external" href="https://scikit-learn.org/stable/modules/model_persistence.html">persistence Example</a>
from scikit-learn.</p>
</details><details class="summary-b-vanilla-auto-sklearn-b">
<summary><b>Vanilla auto-sklearn</b></summary><p>In order to obtain <em>vanilla auto-sklearn</em> as used in <a class="reference external" href="https://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning">Efficient and Robust Automated Machine Learning</a>
set <code class="docutils literal notranslate"><span class="pre">ensemble_size=1</span></code> and <code class="docutils literal notranslate"><span class="pre">initial_configurations_via_metalearning=0</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">autosklearn.classification</span>
<span class="n">automl</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">AutoSklearnClassifier</span><span class="p">(</span>
    <span class="n">ensemble_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">initial_configurations_via_metalearning</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></div>
</div>
<p>An ensemble of size one will result in always choosing the current best model
according to its performance on the validation set. Setting the initial
configurations found by meta-learning to zero makes <em>auto-sklearn</em> use the
regular SMAC algorithm for suggesting new hyperparameter configurations.</p>
</details></div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/manual.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2014-2022, Machine Learning Professorship Freiburg.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>