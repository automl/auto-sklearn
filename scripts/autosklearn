#! /usr/bin/env python
# -*- encoding: utf-8 -*-
from collections import deque
import logging
import random
from multiprocessing import Queue
import os
import pkg_resources
import signal
import shutil
import time

import psutil


import autosklearn.automl
import autosklearn.util.check_pid
from autosklearn.util import logging_
from autosklearn.util import options


if __name__ == '__main__':
    raise NotImplementedError('This does not work at the moment. Please wait '
                              'until the refactoring is done!')
    logging_.setup()
    parser = options.get_options()
    args = parser.parse_args()

    time_limit = args.time_limit
    start_time = time.time()

    # Go to the execution directory
    if args.exec_dir is not None:
        os.chdir(args.exec_dir)

    # Check the output directories
    output_dir = args.output_dir
    tmp_dataset_dir = args.temporary_output_directory

    pid = os.getpid()
    random_number = random.randint(0, 10000)
    remove_output_dir = False
    remove_tmp_dir = False

    if output_dir is None:
        output_dir = '/tmp/autosklearn_output_%d_%d' % (pid, random_number)
        os.makedirs(output_dir)
        remove_output_dir = not args.keep_output
    else:
        if not os.path.isdir(output_dir):
            raise ValueError('If output_dir is specified, it must exist: %s'
                             % output_dir)
        output_dir = os.path.join(output_dir, str(args.seed))
        os.mkdir(output_dir)

    if tmp_dataset_dir is None:
        tmp_dataset_dir = '/tmp/autosklearn_tmp_%d_%d' % (pid, random_number)
        os.makedirs(tmp_dataset_dir)
        remove_tmp_dir = not args.keep_output
    else:
        if not os.path.isdir(tmp_dataset_dir):
            raise ValueError('If tmp_dataset_dir is specified, it must exist: %s'
                             % tmp_dataset_dir)
        tmp_dataset_dir = os.path.join(tmp_dataset_dir)

    logger = logging_.get_logger('autosklearn_%d' % args.seed,
                                 outputdir=tmp_dataset_dir)
    meta_base_logger = logging.getLogger(
        'pyMetaLearn.metalearning.meta_base')
    meta_base_logger.setLevel(logging.DEBUG)
    metalearn_logger = logging.getLogger(
        'pyMetaLearn.optimizers.metalearn_optimizer.metalearner')
    metalearn_logger.setLevel(logging.DEBUG)

    BUFFER = 35  # time-left - BUFFER = timelimit for SMAC/ensemble_script.py
    BUFFER_BEFORE_SENDING_SIGTERM = 30  # We send SIGTERM to all processes
    DELAY_TO_SIGKILL = 15  # And after a delay we send a sigkill

    # Manipulate $PATH so that SMAC and the runsolver are in it.
    smac = pkg_resources.resource_filename(
        'autosklearn',
        'binaries/smac-v2.08.01-development-1/smac-v2.08.01-development-1/')
    runsolver = pkg_resources.resource_filename(
        'autosklearn',
        'binaries/'
    )
    os.environ['PATH'] = smac + os.pathsep + runsolver + os.pathsep + \
        os.environ['PATH']

    time_spent_so_far = time.time() - start_time
    time_left_for_smac = time_limit - time_spent_so_far
    queue = Queue()
    automl = autosklearn.automl.AutoML(
        args.dataset_name, args.data_dir, tmp_dataset_dir,
        output_dir, time_left_for_smac, args.per_run_time_limit,
        log_dir=tmp_dataset_dir, ensemble_size=args.ensemble_size,
        ensemble_nbest=args.ensemble_nbest,
        initial_configurations_via_metalearning=args
        .metalearning_configurations, seed=args.seed,
        ml_memory_limit=args.ml_memory_limit,
        metadata_directory=args.metadata_directory,
        queue=queue)
    automl.start_automl()

    [time_needed_to_load_data, data_manager_file, proc_smac, proc_ensembles] \
        = queue.get()

    # == And now we wait till we run out of time
    while time.time() - start_time <= time_limit - \
            BUFFER_BEFORE_SENDING_SIGTERM:
        time.sleep(1)

    # Kill all children, grand-children and so on
    process = psutil.Process()
    # All children which must be killed
    children = deque()
    children.extendleft(process.children(recursive=True))

    for delay, sig in \
            [(0, signal.SIGINT),
             (BUFFER_BEFORE_SENDING_SIGTERM / 3., signal.SIGTERM),
             (BUFFER_BEFORE_SENDING_SIGTERM / 3. * 2., signal.SIGKILL)]:
        visited = set()

        # first, send SIGINT
        while len(children) > 0:
            child = children.pop()
            # First, check if all children of child are in the children set
            if not child.is_running():
                continue

            try:
                grandchildren = process.children(recursive=True)
                for grandchild in grandchildren:
                    if grandchild in visited:
                        continue
                    else:
                        children.appendleft(grandchild)
            except psutil.NoSuchProcess:
                pass

            # Then, send the signal
            try:
                child.send_signal(sig)
            except psutil.NoSuchProcess:
                pass

            visited.add(child)

        # Readd all children we ever found to the list which were running in
        # the last iteration of killing processes to make sure that we killed
        #  them all.
        children.extendleft(visited)

        while time.time() - start_time <= time_limit - \
                (BUFFER_BEFORE_SENDING_SIGTERM - delay):
            time.sleep(1)

    if remove_output_dir is True:
        shutil.rmtree(output_dir)
    if remove_tmp_dir is True:
        shutil.rmtree(tmp_dataset_dir)
