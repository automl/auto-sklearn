{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending Auto-Sklearn with XGBboost Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:26.324192Z",
     "start_time": "2020-10-30T19:43:25.206242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyparsing.py:3190: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile(self.reString)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 1.2.1\n",
      "autosklearn 0.10.0\n"
     ]
    }
   ],
   "source": [
    "from ConfigSpace.configuration_space import ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, \\\n",
    "    UniformIntegerHyperparameter, CategoricalHyperparameter\n",
    "\n",
    "import sklearn.metrics\n",
    "import autosklearn.regression\n",
    "import autosklearn.pipeline.components.regression\n",
    "from autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm\n",
    "from autosklearn.pipeline.constants import SPARSE, DENSE, \\\n",
    "    SIGNED_DATA, UNSIGNED_DATA, PREDICTIONS\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "print(\"xgb\", xgb.__version__)\n",
    "print(\"autosklearn\", autosklearn.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:26.335719Z",
     "start_time": "2020-10-30T19:43:26.325451Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test XBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:26.338768Z",
     "start_time": "2020-10-30T19:43:26.336900Z"
    }
   },
   "outputs": [],
   "source": [
    "# xgb_model = xgb.XGBRegressor(n_estimators=1)\n",
    "# xgb_model.fit(X_train, y_train, verbose=1)\n",
    "# xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement XBG component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:26.353641Z",
     "start_time": "2020-10-30T19:43:26.339771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    base_score, Type: UniformFloat, Range: [0.1, 1.0], Default: 0.5\n",
      "    booster, Type: Categorical, Choices: {gbtree, gblinear, dart}, Default: gbtree\n",
      "    gamma, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.0\n",
      "    learning_rate, Type: UniformFloat, Range: [1e-07, 1.0], Default: 0.3\n",
      "    max_depth, Type: UniformInteger, Range: [1, 10], Default: 6\n",
      "    min_child_weight, Type: UniformInteger, Range: [1, 10], Default: 1\n",
      "    n_estimators, Type: UniformInteger, Range: [1, 2000], Default: 100\n",
      "    reg_alpha, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.0\n",
      "    reg_lambda, Type: UniformFloat, Range: [0.0, 1.0], Default: 1.0\n",
      "    tree_method, Type: Categorical, Choices: {auto, exact, approx, hist}, Default: auto\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class XGBReg(AutoSklearnRegressionAlgorithm):\n",
    "    def __init__(self, learning_rate, booster, tree_method, gamma, reg_alpha, reg_lambda, base_score, n_estimators, \n",
    "                 max_depth, min_child_weight, random_state=None):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.booster = booster\n",
    "        self.tree_method = tree_method\n",
    "        self.gamma=gamma\n",
    "        self.reg_alpha=reg_alpha\n",
    "        self.reg_lambda=reg_lambda\n",
    "        self.base_score=base_score\n",
    "        self.n_estimators=n_estimators\n",
    "        self.max_depth=max_depth\n",
    "        self.min_child_weight=min_child_weight\n",
    "        \n",
    "        self.random_state = random_state\n",
    "        self.estimator = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        import xgboost as xgb\n",
    "        self.estimator = xgb.XGBRegressor(learning_rate=self.learning_rate, booster=self.booster, \n",
    "                                          tree_method=self.tree_method, gamma=self.gamma, reg_alpha=self.reg_alpha,\n",
    "                                          reg_lambda=self.reg_lambda, base_score=self.base_score, \n",
    "                                          n_estimators=self.n_estimators, max_depth=self.max_depth,\n",
    "                                          min_child_weight = self.min_child_weight)\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.estimator is None:\n",
    "            raise NotImplementedError\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_properties(dataset_properties=None):\n",
    "        return {'shortname': 'XGBReg',\n",
    "                'name': 'XGB Regression',\n",
    "                'handles_regression': True,\n",
    "                'handles_classification': False,\n",
    "                'handles_multiclass': False,\n",
    "                'handles_multilabel': False,\n",
    "                'handles_multioutput': True,\n",
    "                'is_deterministic': True,\n",
    "                'input': (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),\n",
    "                'output': (PREDICTIONS,)}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_hyperparameter_search_space(dataset_properties=None):\n",
    "        cs = ConfigurationSpace()\n",
    "        learning_rate = UniformFloatHyperparameter(\n",
    "            name='learning_rate', lower=10 ** -7, upper=1,default_value=0.3) #log=True\n",
    "        booster = CategoricalHyperparameter(\n",
    "            name='booster',choices=['gbtree','gblinear','dart'],default_value='gbtree') \n",
    "        tree_method = CategoricalHyperparameter(\n",
    "            name='tree_method', choices=['auto','exact','approx', 'hist'], default_value='auto') #'gpu_hist'\n",
    "        gamma = UniformFloatHyperparameter(\n",
    "            name='gamma', lower=0.0000000, upper=1, default_value=0.0) #log=True\n",
    "        reg_alpha = UniformFloatHyperparameter(\n",
    "            name='reg_alpha', lower=0.0000000, upper=1, default_value=0.0) #log=True\n",
    "        reg_lambda = UniformFloatHyperparameter(\n",
    "            name='reg_lambda', lower=0.0000000, upper=1, default_value=1) #log=True\n",
    "        base_score = UniformFloatHyperparameter(\n",
    "            name='base_score', lower=0.1, upper=1, default_value=0.5) #log=True\n",
    "        \n",
    "        n_estimators=UniformIntegerHyperparameter(\n",
    "            name='n_estimators', lower=1, upper=2000, default_value=100)\n",
    "        max_depth=UniformIntegerHyperparameter(\n",
    "            name='max_depth', lower=1, upper=10, default_value=6)\n",
    "        min_child_weight= UniformIntegerHyperparameter(\n",
    "            name='min_child_weight', lower=1, upper=10, default_value=1)\n",
    "\n",
    "        \n",
    "        cs.add_hyperparameters([learning_rate, booster, tree_method, gamma,reg_alpha, reg_lambda,base_score,n_estimators,\n",
    "                               max_depth, min_child_weight])\n",
    "        return cs\n",
    "    \n",
    "# Add XGB component to auto-sklearn.\n",
    "autosklearn.pipeline.components.regression.add_regressor(XGBReg)\n",
    "cs = XGBReg.get_hyperparameter_search_space()\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using the created XBG component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:50.584774Z",
     "start_time": "2020-10-30T19:43:26.354611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:43:28] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:30] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:32] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:32] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:34] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:35] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:40] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { gamma, max_depth, min_child_weight, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(dask_client=None,\n",
       "                     delete_output_folder_after_terminate=True,\n",
       "                     delete_tmp_folder_after_terminate=True,\n",
       "                     disable_evaluator_output=False, ensemble_memory_limit=1024,\n",
       "                     ensemble_nbest=50, ensemble_size=1,\n",
       "                     exclude_estimators=None, exclude_preprocessors=None,\n",
       "                     get_smac_object_callback=None,\n",
       "                     include_estimators=['XGBReg'], include_preprocessors=None,\n",
       "                     initial_configurations_via_metalearning=0,\n",
       "                     logging_config=None, max_models_on_disc=50,\n",
       "                     metadata_directory=None, metric=None, ml_memory_limit=3072,\n",
       "                     n_jobs=None, output_folder=None, per_run_time_limit=10,\n",
       "                     resampling_strategy='holdout',\n",
       "                     resampling_strategy_arguments=None, seed=1,\n",
       "                     smac_scenario_args=None, time_left_for_this_task=30,\n",
       "                     tmp_folder=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=30,\n",
    "    per_run_time_limit=10,\n",
    "    include_estimators=['XGBReg'] \n",
    "    ,ensemble_size=1\n",
    "    ,initial_configurations_via_metalearning=0,\n",
    ")\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print prediction \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:50.599843Z",
     "start_time": "2020-10-30T19:43:50.585727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158.2543335 , 165.25517273, 232.31369019, 171.4210968 ,\n",
       "       180.06288147, 128.54096985, 118.91077423, 171.2124939 ,\n",
       "       212.3092041 , 128.57797241, 116.26277924, 141.31118774,\n",
       "        74.54495239, 118.4146347 , 240.20515442, 185.80239868,\n",
       "       137.2454071 , 117.47792053,  97.5131073 , 247.29804993,\n",
       "       135.97555542, 264.20507812, 102.75144196, 100.00663757,\n",
       "       187.87504578, 144.37947083, 128.80046082, 264.92733765,\n",
       "       181.68066406, 130.91119385, 164.19534302,  65.94696045,\n",
       "       168.15518188, 229.20506287, 104.61754608, 208.60090637,\n",
       "       139.85713196, 140.45094299, 152.35533142, 115.55531311,\n",
       "       181.44374084, 116.09146118, 189.69267273, 129.76060486,\n",
       "       156.42976379, 188.09292603, 153.91339111, 107.44093323,\n",
       "       175.9956665 , 137.43299866, 151.84436035, 154.20431519,\n",
       "       211.23632812, 177.24919128, 216.05328369, 145.0786438 ,\n",
       "       152.38664246,  57.05230331, 129.16923523,  83.51231384,\n",
       "       212.88713074, 106.92141724, 175.31744385,  80.62203217,\n",
       "       173.17692566, 187.30545044, 158.90438843, 198.15155029,\n",
       "       193.19239807, 177.87902832, 130.56356812, 114.01367188,\n",
       "       155.60307312, 161.28167725, 112.85617828, 176.65930176,\n",
       "       264.52722168,  83.3520813 , 115.12510681,  63.58117676,\n",
       "       102.63233185, 272.57675171, 124.39369965,  94.40621948,\n",
       "       199.1965332 , 149.75514221,  72.23696136, 100.8585434 ,\n",
       "       125.81771851,  89.08040619,  71.57009125, 172.61125183,\n",
       "       131.03292847, 179.28817749, 184.92362976, 167.89472961,\n",
       "       146.00764465, 206.13545227, 111.29075623, 160.3704071 ,\n",
       "        90.60933685, 209.97779846,  92.77619171,  95.41629028,\n",
       "       155.01782227, 159.6307373 , 106.37176514, 154.01304626,\n",
       "       136.7883606 ,  70.0718689 , 111.12665558])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:50.604438Z",
     "start_time": "2020-10-30T19:43:50.600748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: f5006b84b27d0942603109061919c7e5\n",
      "  Metric: r2\n",
      "  Best validation score: 0.585748\n",
      "  Number of target algorithm runs: 11\n",
      "  Number of successful target algorithm runs: 10\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 1\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reg.sprint_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print model paramerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T19:43:50.611436Z",
     "start_time": "2020-10-30T19:43:50.605801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score:  -0.15646095406938665\n",
      "[(1.000000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'select_percentile_regression', 'regressor:__choice__': 'XGBReg', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7412066674374952, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.28631016731182696, 'feature_preprocessor:select_percentile_regression:percentile': 71.2593340979654, 'feature_preprocessor:select_percentile_regression:score_func': 'f_regression', 'regressor:XGBReg:base_score': 0.3197409069902052, 'regressor:XGBReg:booster': 'gblinear', 'regressor:XGBReg:gamma': 0.7142038042875509, 'regressor:XGBReg:learning_rate': 0.5722428170485222, 'regressor:XGBReg:max_depth': 8, 'regressor:XGBReg:min_child_weight': 4, 'regressor:XGBReg:n_estimators': 1572, 'regressor:XGBReg:reg_alpha': 0.565152490714025, 'regressor:XGBReg:reg_lambda': 0.4511339750354547, 'regressor:XGBReg:tree_method': 'approx'},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multioutput': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"r2 score: \", sklearn.metrics.r2_score(y_pred, y_test))\n",
    "print(reg.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "364.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
