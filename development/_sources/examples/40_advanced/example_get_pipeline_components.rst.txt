
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_get_pipeline_components.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_get_pipeline_components.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_get_pipeline_components.py:


======================
Obtain run information
======================

The following example shows how to obtain information from a finished
Auto-sklearn run. In particular, it shows:
* how to query which models were evaluated by Auto-sklearn
* how to query the models in the final ensemble
* how to get general statistics on the what Auto-sklearn evaluated

Auto-sklearn is a wrapper on top of
the sklearn models. This example illustrates how to interact
with the sklearn components directly, in this case a PCA preprocessor.

.. GENERATED FROM PYTHON SOURCE LINES 17-25

.. code-block:: default

    from pprint import pprint

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.classification









.. GENERATED FROM PYTHON SOURCE LINES 26-28

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 28-34

.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X, y, random_state=1
    )








.. GENERATED FROM PYTHON SOURCE LINES 35-37

Build and fit the classifier
============================

.. GENERATED FROM PYTHON SOURCE LINES 37-48

.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=30,
        per_run_time_limit=10,
        disable_evaluator_output=False,
        # To simplify querying the models in the final ensemble, we
        # restrict auto-sklearn to use only pca as a preprocessor
        include={"feature_preprocessor": ["pca"]},
    )
    automl.fit(X_train, y_train, dataset_name="breast_cancer")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    AutoSklearnClassifier(ensemble_class=<class 'autosklearn.ensembles.ensemble_selection.EnsembleSelection'>,
                          include={'feature_preprocessor': ['pca']},
                          per_run_time_limit=10, time_left_for_this_task=30)



.. GENERATED FROM PYTHON SOURCE LINES 49-51

Predict using the model
=======================

.. GENERATED FROM PYTHON SOURCE LINES 51-56

.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:{}".format(sklearn.metrics.accuracy_score(y_test, predictions)))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Accuracy score:0.951048951048951




.. GENERATED FROM PYTHON SOURCE LINES 57-73

Report the models found by Auto-Sklearn
=======================================

Auto-sklearn uses
`Ensemble Selection <https://www.cs.cornell.edu/~alexn/papers/shotgun.icml04.revised.rev2.pdf>`_
to construct ensembles in a post-hoc fashion. The ensemble is a linear
weighting of all models constructed during the hyperparameter optimization.
This prints the final ensemble. It is a dictionary where ``model_id`` of
each model is a key, and value is a dictionary containing information
of that model. A model's dict contains its ``'model_id'``, ``'rank'``,
``'cost'``, ``'ensemble_weight'``, and the model itself. The model is
given by the ``'data_preprocessor'``, ``'feature_preprocessor'``,
``'regressor'/'classifier'`` and ``'sklearn_regressor'/'sklearn_classifier'``
entries. But for the ``'cv'`` resampling strategy, the same for each cv
model is stored in the ``'estimators'`` list in the dict, along with the
``'voting_model'``.

.. GENERATED FROM PYTHON SOURCE LINES 73-76

.. code-block:: default


    pprint(automl.show_models(), indent=4)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {   2: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fcac13a1fd0>,
               'cost': 0.07801418439716312,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fcac1148880>,
               'ensemble_weight': 0.2,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fcaacf61070>,
               'model_id': 2,
               'rank': 1,
               'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,
                           random_state=1, warm_start=True)},
        3: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fcaae044970>,
               'cost': 0.07092198581560283,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fcaad3302e0>,
               'ensemble_weight': 0.18,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fcaabf33640>,
               'model_id': 3,
               'rank': 2,
               'sklearn_classifier': RandomForestClassifier(max_features=1, min_samples_leaf=2, min_samples_split=20,
                           n_estimators=512, n_jobs=1, random_state=1,
                           warm_start=True)},
        7: {   'balancing': Balancing(random_state=1, strategy='weighting'),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fcaad923370>,
               'cost': 0.1063829787234043,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fcac13f6400>,
               'ensemble_weight': 0.22,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fcaa5449400>,
               'model_id': 7,
               'rank': 3,
               'sklearn_classifier': LinearSVC(C=10.369811497206404, class_weight='balanced', dual=False,
              intercept_scaling=1.0, random_state=1, tol=0.0015130257264171173)},
        8: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fcaa67a90d0>,
               'cost': 0.028368794326241176,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fcaabac7b50>,
               'ensemble_weight': 0.32,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fcaacea1c70>,
               'model_id': 8,
               'rank': 4,
               'sklearn_classifier': KNeighborsClassifier(n_neighbors=10, p=1)},
        9: {   'balancing': Balancing(random_state=1, strategy='weighting'),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fcaadb77cd0>,
               'cost': 0.08510638297872342,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fcaac9d6340>,
               'ensemble_weight': 0.02,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fcaace5ed90>,
               'model_id': 9,
               'rank': 5,
               'sklearn_classifier': DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                           max_depth=1, min_samples_leaf=12, min_samples_split=13,
                           random_state=1)},
        10: {   'balancing': Balancing(random_state=1),
                'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fcaac1630d0>,
                'cost': 0.07801418439716312,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fcaac06a670>,
                'ensemble_weight': 0.06,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fcaac1631f0>,
                'model_id': 10,
                'rank': 6,
                'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,
                                   l2_regularization=3.511604744219034e-05,
                                   learning_rate=0.06666502293259023, max_iter=512,
                                   max_leaf_nodes=18, min_samples_leaf=5,
                                   n_iter_no_change=0, random_state=1,
                                   validation_fraction=None, warm_start=True)}}




.. GENERATED FROM PYTHON SOURCE LINES 77-82

Report statistics about the search
==================================

Print statistics about the auto-sklearn run such as number of
iterations, number of models failed with a time out etc.

.. GENERATED FROM PYTHON SOURCE LINES 82-84

.. code-block:: default

    print(automl.sprint_statistics())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    auto-sklearn results:
      Dataset name: breast_cancer
      Metric: accuracy
      Best validation score: 0.971631
      Number of target algorithm runs: 9
      Number of successful target algorithm runs: 6
      Number of crashed target algorithm runs: 3
      Number of target algorithms that exceeded the time limit: 0
      Number of target algorithms that exceeded the memory limit: 0





.. GENERATED FROM PYTHON SOURCE LINES 85-92

Detailed statistics about the search - part 1
=============================================

Auto-sklearn also keeps detailed statistics of the hyperparameter
optimization procedurce, which are stored in a so-called
`run history <https://automl.github.io/SMAC3/master/apidoc/smac.
runhistory.runhistory.html#smac.runhistory.runhistory.RunHistory>`_.

.. GENERATED FROM PYTHON SOURCE LINES 92-95

.. code-block:: default


    print(automl.automl_.runhistory_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7fcaad33b940>




.. GENERATED FROM PYTHON SOURCE LINES 96-97

Runs are stored inside an ``OrderedDict`` called ``data``:

.. GENERATED FROM PYTHON SOURCE LINES 97-100

.. code-block:: default


    print(len(automl.automl_.runhistory_.data))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    10




.. GENERATED FROM PYTHON SOURCE LINES 101-102

Let's iterative over all entries

.. GENERATED FROM PYTHON SOURCE LINES 102-108

.. code-block:: default


    for run_key in automl.automl_.runhistory_.data:
        print("#########")
        print(run_key)
        print(automl.automl_.runhistory_.data[run_key])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    #########
    RunKey(config_id=1, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07801418439716312, time=1.8954148292541504, status=<StatusType.SUCCESS: 1>, starttime=1659947714.1986036, endtime=1659947716.1161983, additional_info={'duration': 1.7872860431671143, 'num_run': 2, 'train_loss': 0.0, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=2, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07092198581560283, time=1.6377966403961182, status=<StatusType.SUCCESS: 1>, starttime=1659947716.1807883, endtime=1659947717.8437586, additional_info={'duration': 1.5320842266082764, 'num_run': 3, 'train_loss': 0.06315789473684208, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=3, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=1.0, time=0.39651942253112793, status=<StatusType.CRASHED: 3>, starttime=1659947717.9503915, endtime=1659947718.3698292, additional_info={'traceback': 'Traceback (most recent call last):\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/__init__.py", line 55, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/train_evaluator.py", line 1283, in eval_holdout\n    evaluator = TrainEvaluator(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/train_evaluator.py", line 231, in __init__\n    super().__init__(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/abstract_evaluator.py", line 303, in __init__\n    self.model = self._get_model(feat_type=self.feat_type)\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/abstract_evaluator.py", line 327, in _get_model\n    model = self.model_class(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/classification.py", line 88, in __init__\n    super().__init__(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/base.py", line 90, in __init__\n    self.set_hyperparameters(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/base.py", line 233, in set_hyperparameters\n    sub_configuration = Configuration(\n  File "ConfigSpace/configuration_space.pyx", line 1465, in ConfigSpace.configuration_space.Configuration.__init__\n  File "ConfigSpace/configuration_space.pyx", line 1495, in ConfigSpace.configuration_space.Configuration.is_valid_configuration\n  File "ConfigSpace/c_util.pyx", line 38, in ConfigSpace.c_util.check_configuration\n  File "ConfigSpace/c_util.pyx", line 113, in ConfigSpace.c_util.check_configuration\nValueError: Inactive hyperparameter \'random_forest:bootstrap\' must not be specified, but has the vector value: \'0.0\'.\n', 'error': 'ValueError("Inactive hyperparameter \'random_forest:bootstrap\' must not be specified, but has the vector value: \'0.0\'.")', 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=4, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=1.0, time=0.39916133880615234, status=<StatusType.CRASHED: 3>, starttime=1659947718.4279761, endtime=1659947718.85084, additional_info={'traceback': 'Traceback (most recent call last):\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/__init__.py", line 55, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/train_evaluator.py", line 1283, in eval_holdout\n    evaluator = TrainEvaluator(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/train_evaluator.py", line 231, in __init__\n    super().__init__(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/abstract_evaluator.py", line 303, in __init__\n    self.model = self._get_model(feat_type=self.feat_type)\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/abstract_evaluator.py", line 327, in _get_model\n    model = self.model_class(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/classification.py", line 88, in __init__\n    super().__init__(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/base.py", line 90, in __init__\n    self.set_hyperparameters(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/base.py", line 233, in set_hyperparameters\n    sub_configuration = Configuration(\n  File "ConfigSpace/configuration_space.pyx", line 1465, in ConfigSpace.configuration_space.Configuration.__init__\n  File "ConfigSpace/configuration_space.pyx", line 1495, in ConfigSpace.configuration_space.Configuration.is_valid_configuration\n  File "ConfigSpace/c_util.pyx", line 38, in ConfigSpace.c_util.check_configuration\n  File "ConfigSpace/c_util.pyx", line 113, in ConfigSpace.c_util.check_configuration\nValueError: Inactive hyperparameter \'random_forest:bootstrap\' must not be specified, but has the vector value: \'0.0\'.\n', 'error': 'ValueError("Inactive hyperparameter \'random_forest:bootstrap\' must not be specified, but has the vector value: \'0.0\'.")', 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=5, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=1.0, time=0.3861730098724365, status=<StatusType.CRASHED: 3>, starttime=1659947718.9102733, endtime=1659947719.3205373, additional_info={'traceback': 'Traceback (most recent call last):\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/__init__.py", line 55, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/train_evaluator.py", line 1283, in eval_holdout\n    evaluator = TrainEvaluator(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/train_evaluator.py", line 231, in __init__\n    super().__init__(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/abstract_evaluator.py", line 303, in __init__\n    self.model = self._get_model(feat_type=self.feat_type)\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/evaluation/abstract_evaluator.py", line 327, in _get_model\n    model = self.model_class(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/classification.py", line 88, in __init__\n    super().__init__(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/base.py", line 90, in __init__\n    self.set_hyperparameters(\n  File "/home/runner/work/auto-sklearn/auto-sklearn/autosklearn/pipeline/base.py", line 233, in set_hyperparameters\n    sub_configuration = Configuration(\n  File "ConfigSpace/configuration_space.pyx", line 1465, in ConfigSpace.configuration_space.Configuration.__init__\n  File "ConfigSpace/configuration_space.pyx", line 1495, in ConfigSpace.configuration_space.Configuration.is_valid_configuration\n  File "ConfigSpace/c_util.pyx", line 38, in ConfigSpace.c_util.check_configuration\n  File "ConfigSpace/c_util.pyx", line 113, in ConfigSpace.c_util.check_configuration\nValueError: Inactive hyperparameter \'random_forest:bootstrap\' must not be specified, but has the vector value: \'0.0\'.\n', 'error': 'ValueError("Inactive hyperparameter \'random_forest:bootstrap\' must not be specified, but has the vector value: \'0.0\'.")', 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=6, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.1063829787234043, time=0.8524551391601562, status=<StatusType.SUCCESS: 1>, starttime=1659947721.2428343, endtime=1659947722.1189635, additional_info={'duration': 0.7671198844909668, 'num_run': 7, 'train_loss': 0.1473684210526316, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=7, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.028368794326241176, time=0.8221778869628906, status=<StatusType.SUCCESS: 1>, starttime=1659947724.0912135, endtime=1659947724.939363, additional_info={'duration': 0.7389366626739502, 'num_run': 8, 'train_loss': 0.03157894736842104, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=8, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.08510638297872342, time=0.8579308986663818, status=<StatusType.SUCCESS: 1>, starttime=1659947725.0954187, endtime=1659947725.978314, additional_info={'duration': 0.7715115547180176, 'num_run': 9, 'train_loss': 0.07017543859649122, 'configuration_origin': 'Random Search'})
    #########
    RunKey(config_id=9, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07801418439716312, time=1.5020191669464111, status=<StatusType.SUCCESS: 1>, starttime=1659947728.308553, endtime=1659947729.8405514, additional_info={'duration': 1.4132287502288818, 'num_run': 10, 'train_loss': 0.0, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=10, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=1.0, time=0.0, status=<StatusType.STOP: 8>, starttime=1659947732.5251546, endtime=1659947732.525155, additional_info={})




.. GENERATED FROM PYTHON SOURCE LINES 109-110

and have a detailed look at one entry:

.. GENERATED FROM PYTHON SOURCE LINES 110-114

.. code-block:: default


    run_key = list(automl.automl_.runhistory_.data.keys())[0]
    run_value = automl.automl_.runhistory_.data[run_key]








.. GENERATED FROM PYTHON SOURCE LINES 115-116

The ``run_key`` contains all information describing a run:

.. GENERATED FROM PYTHON SOURCE LINES 116-122

.. code-block:: default


    print("Configuration ID:", run_key.config_id)
    print("Instance:", run_key.instance_id)
    print("Seed:", run_key.seed)
    print("Budget:", run_key.budget)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Configuration ID: 1
    Instance: {"task_id": "breast_cancer"}
    Seed: 0
    Budget: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 123-124

and the configuration can be looked up in the run history as well:

.. GENERATED FROM PYTHON SOURCE LINES 124-127

.. code-block:: default


    print(automl.automl_.runhistory_.ids_config[run_key.config_id])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Configuration(values={
      'balancing:strategy': 'none',
      'classifier:__choice__': 'random_forest',
      'classifier:random_forest:bootstrap': 'True',
      'classifier:random_forest:criterion': 'gini',
      'classifier:random_forest:max_depth': 'None',
      'classifier:random_forest:max_features': 0.5,
      'classifier:random_forest:max_leaf_nodes': 'None',
      'classifier:random_forest:min_impurity_decrease': 0.0,
      'classifier:random_forest:min_samples_leaf': 1,
      'classifier:random_forest:min_samples_split': 2,
      'classifier:random_forest:min_weight_fraction_leaf': 0.0,
      'data_preprocessor:__choice__': 'feature_type',
      'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean',
      'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize',
      'feature_preprocessor:__choice__': 'pca',
      'feature_preprocessor:pca:keep_variance': 0.9999,
      'feature_preprocessor:pca:whiten': 'False',
    })





.. GENERATED FROM PYTHON SOURCE LINES 128-134

The only other important entry is the budget in case you are using
auto-sklearn with
:ref:`sphx_glr_examples_60_search_example_successive_halving.py`.
The remaining parts of the key can be ignored for auto-sklearn and are
only there because the underlying optimizer, SMAC, can handle more general
problems, too.

.. GENERATED FROM PYTHON SOURCE LINES 136-137

The ``run_value`` contains all output from running the configuration:

.. GENERATED FROM PYTHON SOURCE LINES 137-145

.. code-block:: default


    print("Cost:", run_value.cost)
    print("Time:", run_value.time)
    print("Status:", run_value.status)
    print("Additional information:", run_value.additional_info)
    print("Start time:", run_value.starttime)
    print("End time", run_value.endtime)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Cost: 0.07801418439716312
    Time: 1.8954148292541504
    Status: StatusType.SUCCESS
    Additional information: {'duration': 1.7872860431671143, 'num_run': 2, 'train_loss': 0.0, 'configuration_origin': 'Initial design'}
    Start time: 1659947714.1986036
    End time 1659947716.1161983




.. GENERATED FROM PYTHON SOURCE LINES 146-152

Cost is basically the same as a loss. In case the metric to optimize for
should be maximized, it is internally transformed into a minimization
metric. Additionally, the status type gives information on whether the run
was successful, while the additional information's most interesting entry
is the internal training loss. Furthermore, there is detailed information
on the runtime available.

.. GENERATED FROM PYTHON SOURCE LINES 154-157

As an example, let's find the best configuration evaluated. As
Auto-sklearn solves a minimization problem internally, we need to look
for the entry with the lowest loss:

.. GENERATED FROM PYTHON SOURCE LINES 157-169

.. code-block:: default


    losses_and_configurations = [
        (run_value.cost, run_key.config_id)
        for run_key, run_value in automl.automl_.runhistory_.data.items()
    ]
    losses_and_configurations.sort()
    print("Lowest loss:", losses_and_configurations[0][0])
    print(
        "Best configuration:",
        automl.automl_.runhistory_.ids_config[losses_and_configurations[0][1]],
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Lowest loss: 0.028368794326241176
    Best configuration: Configuration(values={
      'balancing:strategy': 'none',
      'classifier:__choice__': 'k_nearest_neighbors',
      'classifier:k_nearest_neighbors:n_neighbors': 10,
      'classifier:k_nearest_neighbors:p': 1,
      'classifier:k_nearest_neighbors:weights': 'uniform',
      'data_preprocessor:__choice__': 'feature_type',
      'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'median',
      'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'quantile_transformer',
      'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1866,
      'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',
      'feature_preprocessor:__choice__': 'pca',
      'feature_preprocessor:pca:keep_variance': 0.9923006586696794,
      'feature_preprocessor:pca:whiten': 'False',
    })





.. GENERATED FROM PYTHON SOURCE LINES 170-177

Detailed statistics about the search - part 2
=============================================

To maintain compatibility with scikit-learn, Auto-sklearn gives the
same data as
`cv_results_ <https://scikit-learn.org/stable/modules/generated/sklearn.
model_selection.GridSearchCV.html>`_.

.. GENERATED FROM PYTHON SOURCE LINES 177-180

.. code-block:: default


    print(automl.cv_results_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {'mean_test_score': array([0.92198582, 0.92907801, 0.        , 0.        , 0.        ,
           0.89361702, 0.97163121, 0.91489362, 0.92198582]), 'rank_test_scores': array([3, 2, 7, 7, 7, 6, 1, 5, 3]), 'mean_fit_time': array([1.89541483, 1.63779664, 0.39651942, 0.39916134, 0.38617301,
           0.85245514, 0.82217789, 0.8579309 , 1.50201917]), 'params': [{'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:pca:keep_variance': 0.9999, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.9331254454871041, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 2, 'classifier:random_forest:min_samples_split': 20, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:pca:keep_variance': 0.9967857433838874, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'mlp', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:mlp:activation': 'tanh', 'classifier:mlp:alpha': 1.103855734598575e-05, 'classifier:mlp:batch_size': 'auto', 'classifier:mlp:beta_1': 0.9, 'classifier:mlp:beta_2': 0.999, 'classifier:mlp:early_stopping': 'valid', 'classifier:mlp:epsilon': 1e-08, 'classifier:mlp:hidden_layer_depth': 3, 'classifier:mlp:learning_rate_init': 0.00014375616988222174, 'classifier:mlp:n_iter_no_change': 32, 'classifier:mlp:num_nodes_per_layer': 229, 'classifier:mlp:shuffle': 'True', 'classifier:mlp:solver': 'adam', 'classifier:mlp:tol': 0.0001, 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:pca:keep_variance': 0.7895711479212801, 'feature_preprocessor:pca:whiten': 'True', 'classifier:mlp:validation_fraction': 0.1, 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 180, 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'k_nearest_neighbors', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:k_nearest_neighbors:n_neighbors': 4, 'classifier:k_nearest_neighbors:p': 2, 'classifier:k_nearest_neighbors:weights': 'distance', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:pca:keep_variance': 0.8047274080856589, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'libsvm_svc', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:libsvm_svc:C': 100.5905006626969, 'classifier:libsvm_svc:gamma': 0.011333066835975528, 'classifier:libsvm_svc:kernel': 'poly', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'True', 'classifier:libsvm_svc:tol': 0.012391313886912093, 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:pca:keep_variance': 0.9290439925152777, 'feature_preprocessor:pca:whiten': 'False', 'classifier:libsvm_svc:coef0': 0.08087614244138486, 'classifier:libsvm_svc:degree': 3}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'liblinear_svc', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:liblinear_svc:C': 10.369811497206404, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 0.0015130257264171173, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'median', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:pca:keep_variance': 0.5306607720040878, 'feature_preprocessor:pca:whiten': 'False', 'data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_max': 0.9866104280704078, 'data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_min': 0.20576464288464985}, {'balancing:strategy': 'none', 'classifier:__choice__': 'k_nearest_neighbors', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:k_nearest_neighbors:n_neighbors': 10, 'classifier:k_nearest_neighbors:p': 1, 'classifier:k_nearest_neighbors:weights': 'uniform', 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'median', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:pca:keep_variance': 0.9923006586696794, 'feature_preprocessor:pca:whiten': 'False', 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1866, 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'decision_tree', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:decision_tree:criterion': 'entropy', 'classifier:decision_tree:max_depth_factor': 0.07400222370559417, 'classifier:decision_tree:max_features': 1.0, 'classifier:decision_tree:max_leaf_nodes': 'None', 'classifier:decision_tree:min_impurity_decrease': 0.0, 'classifier:decision_tree:min_samples_leaf': 12, 'classifier:decision_tree:min_samples_split': 13, 'classifier:decision_tree:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:pca:keep_variance': 0.9710934401815425, 'feature_preprocessor:pca:whiten': 'True'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:gradient_boosting:early_stop': 'off', 'classifier:gradient_boosting:l2_regularization': 3.511604744219034e-05, 'classifier:gradient_boosting:learning_rate': 0.06666502293259023, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 18, 'classifier:gradient_boosting:min_samples_leaf': 5, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:pca:keep_variance': 0.9968418627262279, 'feature_preprocessor:pca:whiten': 'True'}], 'status': ['Success', 'Success', 'Crash', 'Crash', 'Crash', 'Success', 'Success', 'Success', 'Success'], 'budgets': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'param_balancing:strategy': masked_array(data=['none', 'none', 'weighting', 'weighting', 'none',
                       'weighting', 'none', 'weighting', 'none'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U9'), 'param_classifier:__choice__': masked_array(data=['random_forest', 'random_forest', 'mlp',
                       'k_nearest_neighbors', 'libsvm_svc', 'liblinear_svc',
                       'k_nearest_neighbors', 'decision_tree',
                       'gradient_boosting'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U19'), 'param_data_preprocessor:__choice__': masked_array(data=['feature_type', 'feature_type', 'feature_type',
                       'feature_type', 'feature_type', 'feature_type',
                       'feature_type', 'feature_type', 'feature_type'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U12'), 'param_feature_preprocessor:__choice__': masked_array(data=['pca', 'pca', 'pca', 'pca', 'pca', 'pca', 'pca', 'pca',
                       'pca'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U3'), 'param_classifier:adaboost:algorithm': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:adaboost:learning_rate': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:adaboost:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:adaboost:n_estimators': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:bernoulli_nb:alpha': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:bernoulli_nb:fit_prior': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:criterion': masked_array(data=[--, --, --, --, --, --, --, 'entropy', --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:decision_tree:max_depth_factor': masked_array(data=[--, --, --, --, --, --, --, 0.07400222370559417, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:max_features': masked_array(data=[--, --, --, --, --, --, --, 1.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, 'None', --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:decision_tree:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --, 0.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, 12.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, 13.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --, 0.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:gradient_boosting:early_stop': masked_array(data=[--, --, --, --, --, --, --, --, 'off'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:l2_regularization': masked_array(data=[--, --, --, --, --, --, --, --, 3.511604744219034e-05],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, --, --, --, 0.06666502293259023],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:loss': masked_array(data=[--, --, --, --, --, --, --, --, 'auto'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:max_bins': masked_array(data=[--, --, --, --, --, --, --, --, 255.0],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, 'None'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, 18.0],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, 5.0],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:scoring': masked_array(data=[--, --, --, --, --, --, --, --, 'loss'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:tol': masked_array(data=[--, --, --, --, --, --, --, --, 1e-07],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, 4.0, --, --, 10.0, --, --],
                 mask=[ True,  True,  True, False,  True,  True, False,  True,
                        True],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:p': masked_array(data=[--, --, --, 2.0, --, --, 1.0, --, --],
                 mask=[ True,  True,  True, False,  True,  True, False,  True,
                        True],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:weights': masked_array(data=[--, --, --, 'distance', --, --, 'uniform', --, --],
                 mask=[ True,  True,  True, False,  True,  True, False,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:lda:shrinkage': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:tol': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:C': masked_array(data=[--, --, --, --, --, 10.369811497206404, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:liblinear_svc:dual': masked_array(data=[--, --, --, --, --, 'False', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:fit_intercept': masked_array(data=[--, --, --, --, --, 'True', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:intercept_scaling': masked_array(data=[--, --, --, --, --, 1.0, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:liblinear_svc:loss': masked_array(data=[--, --, --, --, --, 'squared_hinge', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:multi_class': masked_array(data=[--, --, --, --, --, 'ovr', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:penalty': masked_array(data=[--, --, --, --, --, 'l2', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:tol': masked_array(data=[--, --, --, --, --, 0.0015130257264171173, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:C': masked_array(data=[--, --, --, --, 100.5905006626969, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:gamma': masked_array(data=[--, --, --, --, 0.011333066835975528, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:kernel': masked_array(data=[--, --, --, --, 'poly', --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:libsvm_svc:max_iter': masked_array(data=[--, --, --, --, -1.0, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:shrinking': masked_array(data=[--, --, --, --, 'True', --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:libsvm_svc:tol': masked_array(data=[--, --, --, --, 0.012391313886912093, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:activation': masked_array(data=[--, --, 'tanh', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:alpha': masked_array(data=[--, --, 1.103855734598575e-05, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:batch_size': masked_array(data=[--, --, 'auto', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:beta_1': masked_array(data=[--, --, 0.9, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:beta_2': masked_array(data=[--, --, 0.999, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:early_stopping': masked_array(data=[--, --, 'valid', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:epsilon': masked_array(data=[--, --, 1e-08, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:hidden_layer_depth': masked_array(data=[--, --, 3.0, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:learning_rate_init': masked_array(data=[--, --, 0.00014375616988222174, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:n_iter_no_change': masked_array(data=[--, --, 32.0, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:num_nodes_per_layer': masked_array(data=[--, --, 229.0, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:shuffle': masked_array(data=[--, --, 'True', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:solver': masked_array(data=[--, --, 'adam', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:tol': masked_array(data=[--, --, 0.0001, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:passive_aggressive:C': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:average': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:fit_intercept': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:loss': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:tol': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:qda:reg_param': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:random_forest:bootstrap': masked_array(data=['True', 'True', 'True', 'True', 'True', --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:max_depth': masked_array(data=['None', 'None', 'None', 'None', 'None', --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:max_features': masked_array(data=[0.5, 0.9331254454871041, 0.5, 0.5, 0.5, --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:max_leaf_nodes': masked_array(data=['None', 'None', 'None', 'None', 'None', --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:min_impurity_decrease': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:min_samples_leaf': masked_array(data=[1.0, 2.0, 1.0, 1.0, 1.0, --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:min_samples_split': masked_array(data=[2.0, 20.0, 2.0, 2.0, 2.0, --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, --, --, --, --],
                 mask=[False, False, False, False, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:sgd:alpha': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:average': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:fit_intercept': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:learning_rate': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:loss': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:penalty': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:tol': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessor:feature_type:numerical_transformer:imputation:strategy': masked_array(data=['mean', 'mean', 'most_frequent', 'mean', 'mean',
                       'median', 'median', 'most_frequent', 'mean'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U13'), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': masked_array(data=['standardize', 'none', 'quantile_transformer',
                       'normalize', 'minmax', 'robust_scaler',
                       'quantile_transformer', 'standardize', 'none'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U20'), 'param_feature_preprocessor:pca:keep_variance': masked_array(data=[0.9999, 0.9967857433838874, 0.7895711479212801,
                       0.8047274080856589, 0.9290439925152777,
                       0.5306607720040878, 0.9923006586696794,
                       0.9710934401815425, 0.9968418627262279],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value=1e+20), 'param_feature_preprocessor:pca:whiten': masked_array(data=['False', 'False', 'True', 'False', 'False', 'False',
                       'False', 'True', 'True'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U5'), 'param_classifier:gradient_boosting:n_iter_no_change': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:gradient_boosting:validation_fraction': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:shrinkage_factor': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:coef0': masked_array(data=[--, --, --, --, 0.08087614244138486, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:degree': masked_array(data=[--, --, --, --, 3.0, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:validation_fraction': masked_array(data=[--, --, 0.1, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:sgd:epsilon': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:eta0': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:l1_ratio': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:power_t': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, 180.0, --, --, --, 1866.0, --, --],
                 mask=[ True,  True, False,  True,  True,  True, False,  True,
                        True],
           fill_value=1e+20), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, 'uniform', --, --, --, 'normal', --, --],
                 mask=[ True,  True, False,  True,  True,  True, False,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, --, 0.9866104280704078, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, --, 0.20576464288464985, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20)}




.. GENERATED FROM PYTHON SOURCE LINES 181-186

Inspect the components of the best model
========================================

Iterate over the components of the model and print
The explained variance ratio per stage

.. GENERATED FROM PYTHON SOURCE LINES 186-199

.. code-block:: default

    for i, (weight, pipeline) in enumerate(automl.get_models_with_weights()):
        for stage_name, component in pipeline.named_steps.items():
            if "feature_preprocessor" in stage_name:
                print(
                    "The {}th pipeline has a explained variance of {}".format(
                        i,
                        # The component is an instance of AutoSklearnChoice.
                        # Access the sklearn object via the choice attribute
                        # We want the explained variance attributed of
                        # each principal component
                        component.choice.preprocessor.explained_variance_ratio_,
                    )
                )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The 0th pipeline has a explained variance of [0.46038401 0.16124884 0.09747816 0.06923404 0.06142479 0.03312917
     0.03182802 0.01555463 0.01348582 0.00965531 0.00870982 0.007397
     0.00547082 0.00443245 0.00396559 0.00313575 0.0022883  0.00195796
     0.00156348]
    The 1th pipeline has a explained variance of [0.72985767]
    The 2th pipeline has a explained variance of [4.32956881e-01 1.79057296e-01 1.11737571e-01 6.80724345e-02
     5.94611519e-02 3.70629898e-02 2.38430977e-02 1.49326086e-02
     1.37641366e-02 1.13704890e-02 1.03737258e-02 8.74116751e-03
     7.57629717e-03 4.86528503e-03 3.32225143e-03 2.55773043e-03
     2.20759805e-03 1.88675402e-03 1.36245140e-03 1.03409213e-03
     8.39749085e-04 7.91287172e-04 6.75655689e-04 5.42961621e-04
     5.02641737e-04 2.07827509e-04 1.74597367e-04]
    The 3th pipeline has a explained variance of [0.98080571 0.01684553]
    The 4th pipeline has a explained variance of [0.98080571 0.01684553]
    The 5th pipeline has a explained variance of [0.43295688 0.1790573  0.11173757 0.06807243 0.05946115 0.03706299
     0.0238431  0.01493261 0.01376414 0.01137049 0.01037373 0.00874117]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  24.736 seconds)


.. _sphx_glr_download_examples_40_advanced_example_get_pipeline_components.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/40_advanced/example_get_pipeline_components.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_get_pipeline_components.py <example_get_pipeline_components.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_get_pipeline_components.ipynb <example_get_pipeline_components.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
