.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_get_pipeline_components.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_examples_40_advanced_example_get_pipeline_components.py:


======================
Obtain run information
======================

The following example shows how to obtain information from a finished
Auto-sklearn run. In particular, it shows:
* how to query which models were evaluated by Auto-sklearn
* how to query the models in the final ensemble
* how to get general statistics on the what Auto-sklearn evaluated

Auto-sklearn is a wrapper on top of
the sklearn models. This example illustrates how to interact
with the sklearn components directly, in this case a PCA preprocessor.


.. code-block:: default

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.classification








Data Loading
============


.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








Build and fit the classifier
============================


.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=30,
        per_run_time_limit=10,
        disable_evaluator_output=False,
        # To simplify querying the models in the final ensemble, we
        # restrict auto-sklearn to use only pca as a preprocessor
        include_preprocessors=['pca'],
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(include_preprocessors=['pca'], load_models=None,
                          per_run_time_limit=10, time_left_for_this_task=30)



Predict using the model
=======================


.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:{}".format(
        sklearn.metrics.accuracy_score(y_test, predictions))
    )






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score:0.951048951048951




Report the models found by Auto-Sklearn
=======================================

Auto-sklearn uses
`Ensemble Selection <https://www.cs.cornell.edu/~alexn/papers/shotgun.icml04.revised.rev2.pdf>`_
to construct ensembles in a post-hoc fashion. The ensemble is a linear
weighting of all models constructed during the hyperparameter optimization.
This prints the final ensemble. It is a list of tuples, each tuple being
the model weight in the ensemble and the model itself.


.. code-block:: default


    print(automl.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(0.280000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'adaboost', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'pca', 'classifier:adaboost:algorithm': 'SAMME', 'classifier:adaboost:learning_rate': 0.011233995624432622, 'classifier:adaboost:max_depth': 9, 'classifier:adaboost:n_estimators': 477, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018370622484682127, 'feature_preprocessor:pca:keep_variance': 0.6039710338898471, 'feature_preprocessor:pca:whiten': 'False'},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    (0.260000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'pca', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01, 'feature_preprocessor:pca:keep_variance': 0.9999, 'feature_preprocessor:pca:whiten': 'False'},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    (0.260000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'adaboost', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'pca', 'classifier:adaboost:algorithm': 'SAMME', 'classifier:adaboost:learning_rate': 1.4120696722366737, 'classifier:adaboost:max_depth': 8, 'classifier:adaboost:n_estimators': 489, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.011307840322412704, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7357867136119712, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2832469215827823, 'feature_preprocessor:pca:keep_variance': 0.99855313014133, 'feature_preprocessor:pca:whiten': 'True'},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    (0.100000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'bernoulli_nb', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'pca', 'classifier:bernoulli_nb:alpha': 0.011929966129087241, 'classifier:bernoulli_nb:fit_prior': 'True', 'feature_preprocessor:pca:keep_variance': 0.5976152033262122, 'feature_preprocessor:pca:whiten': 'False'},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    (0.080000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'gaussian_nb', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'pca', 'feature_preprocessor:pca:keep_variance': 0.5632675578693742, 'feature_preprocessor:pca:whiten': 'False'},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    (0.020000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'pca', 'classifier:gradient_boosting:early_stop': 'train', 'classifier:gradient_boosting:l2_regularization': 4.187065920024372e-09, 'classifier:gradient_boosting:learning_rate': 0.26826945251088985, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 5, 'classifier:gradient_boosting:min_samples_leaf': 20, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.720514537267965, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27686628712984507, 'feature_preprocessor:pca:keep_variance': 0.6428535788511281, 'feature_preprocessor:pca:whiten': 'True', 'classifier:gradient_boosting:n_iter_no_change': 14},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    ]




Report statistics about the search
==================================

Print statistics about the auto-sklearn run such as number of
iterations, number of models failed with a time out etc.


.. code-block:: default

    print(automl.sprint_statistics())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    auto-sklearn results:
      Dataset name: breast_cancer
      Metric: accuracy
      Best validation score: 0.957447
      Number of target algorithm runs: 7
      Number of successful target algorithm runs: 6
      Number of crashed target algorithm runs: 1
      Number of target algorithms that exceeded the time limit: 0
      Number of target algorithms that exceeded the memory limit: 0





Detailed statistics about the search - part 1
=============================================

Auto-sklearn also keeps detailed statistics of the hyperparameter
optimization procedurce, which are stored in a so-called
`run history <https://automl.github.io/SMAC3/master/apidoc/smac.
runhistory.runhistory.html#smac.runhistory# .runhistory.RunHistory>`_.


.. code-block:: default


    print(automl.automl_.runhistory_)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7fb64c1bce50>




Runs are stored inside an ``OrderedDict`` called ``data``:


.. code-block:: default


    print(len(automl.automl_.runhistory_.data))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    9




Let's iterative over all entries


.. code-block:: default


    for run_key in automl.automl_.runhistory_.data:
        print('#########')
        print(run_key)
        print(automl.automl_.runhistory_.data[run_key])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    #########
    RunKey(config_id=1, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.08510638297872342, time=1.1239774227142334, status=<StatusType.SUCCESS: 1>, starttime=1605566517.1818194, endtime=1605566518.3181508, additional_info={'duration': 1.0815339088439941, 'num_run': 2, 'train_loss': 0.0, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=2, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.08510638297872342, time=0.21181154251098633, status=<StatusType.SUCCESS: 1>, starttime=1605566518.3739693, endtime=1605566518.5958495, additional_info={'duration': 0.19146251678466797, 'num_run': 3, 'train_loss': 0.0, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=3, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.04255319148936165, time=0.3204023838043213, status=<StatusType.SUCCESS: 1>, starttime=1605566518.9629624, endtime=1605566519.3132558, additional_info={'duration': 0.28620409965515137, 'num_run': 4, 'train_loss': 0.0, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=4, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=1.0, time=0.0, status=<StatusType.CRASHED: 3>, starttime=1605566520.7789679, endtime=1605566530.7969918, additional_info={'traceback': 'Traceback (most recent call last):\n  File "/home/travis/miniconda/envs/testenv/lib/python3.7/site-packages/auto_sklearn-0.11.1-py3.7.egg/autosklearn/evaluation/__init__.py", line 291, in run\n    obj(**obj_kwargs)\n  File "/home/travis/miniconda/envs/testenv/lib/python3.7/site-packages/pynisher/limit_function_call.py", line 276, in __call__\n    with open(os.path.join(tmp_dir.name, \'std.out\'), \'r\') as fh:\nFileNotFoundError: [Errno 2] No such file or directory: \'/tmp/tmpy5_ro3ki/std.out\'\n', 'error': "FileNotFoundError(2, 'No such file or directory')"})
    #########
    RunKey(config_id=5, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.12056737588652477, time=0.3274874687194824, status=<StatusType.SUCCESS: 1>, starttime=1605566531.1674771, endtime=1605566531.5162127, additional_info={'duration': 0.2943284511566162, 'num_run': 6, 'train_loss': 0.11929824561403513, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=6, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07092198581560283, time=0.2824690341949463, status=<StatusType.SUCCESS: 1>, starttime=1605566533.3287182, endtime=1605566533.621837, additional_info={'duration': 0.26176905632019043, 'num_run': 7, 'train_loss': 0.11929824561403513, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=7, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.11347517730496459, time=0.7283220291137695, status=<StatusType.SUCCESS: 1>, starttime=1605566533.9983013, endtime=1605566534.7643554, additional_info={'duration': 0.6883361339569092, 'num_run': 8, 'train_loss': 0.0035087719298245723, 'configuration_origin': 'Random Search'})
    #########
    RunKey(config_id=8, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=2147483647.0, time=0.0, status=<StatusType.RUNNING: 9>, starttime=0.0, endtime=0.0, additional_info=None)
    #########
    RunKey(config_id=9, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=2147483647.0, time=0.0, status=<StatusType.RUNNING: 9>, starttime=0.0, endtime=0.0, additional_info=None)




and have a detailed look at one entry:


.. code-block:: default


    run_key = list(automl.automl_.runhistory_.data.keys())[0]
    run_value = automl.automl_.runhistory_.data[run_key]








The ``run_key`` contains all information describing a run:


.. code-block:: default


    print("Configuration ID:", run_key.config_id)
    print("Instance:", run_key.instance_id)
    print("Seed:", run_key.seed)
    print("Budget:", run_key.budget)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Configuration ID: 1
    Instance: {"task_id": "breast_cancer"}
    Seed: 0
    Budget: 0.0




and the configuration can be looked up in the run history as well:


.. code-block:: default


    print(automl.automl_.runhistory_.ids_config[run_key.config_id])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Configuration:
      balancing:strategy, Value: 'none'
      classifier:__choice__, Value: 'random_forest'
      classifier:random_forest:bootstrap, Value: 'True'
      classifier:random_forest:criterion, Value: 'gini'
      classifier:random_forest:max_depth, Constant: 'None'
      classifier:random_forest:max_features, Value: 0.5
      classifier:random_forest:max_leaf_nodes, Constant: 'None'
      classifier:random_forest:min_impurity_decrease, Constant: 0.0
      classifier:random_forest:min_samples_leaf, Value: 1
      classifier:random_forest:min_samples_split, Value: 2
      classifier:random_forest:min_weight_fraction_leaf, Constant: 0.0
      data_preprocessing:categorical_transformer:categorical_encoding:__choice__, Value: 'one_hot_encoding'
      data_preprocessing:categorical_transformer:category_coalescence:__choice__, Value: 'minority_coalescer'
      data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction, Value: 0.01
      data_preprocessing:numerical_transformer:imputation:strategy, Value: 'mean'
      data_preprocessing:numerical_transformer:rescaling:__choice__, Value: 'standardize'
      feature_preprocessor:__choice__, Value: 'pca'
      feature_preprocessor:pca:keep_variance, Value: 0.9999
      feature_preprocessor:pca:whiten, Value: 'False'





The only other important entry is the budget in case you are using
auto-sklearn with
`successive halving <../60_search/example_successive_halving.html>`_.
The remaining parts of the key can be ignored for auto-sklearn and are
only there because the underlying optimizer, SMAC, can handle more general
problems, too.

The ``run_value`` contains all output from running the configuration:


.. code-block:: default


    print("Cost:", run_value.cost)
    print("Time:", run_value.time)
    print("Status:", run_value.status)
    print("Additional information:", run_value.additional_info)
    print("Start time:", run_value.starttime)
    print("End time", run_value.endtime)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Cost: 0.08510638297872342
    Time: 1.1239774227142334
    Status: StatusType.SUCCESS
    Additional information: {'duration': 1.0815339088439941, 'num_run': 2, 'train_loss': 0.0, 'configuration_origin': 'Initial design'}
    Start time: 1605566517.1818194
    End time 1605566518.3181508




Cost is basically the same as a loss. In case the metric to optimize for
should be maximized, it is internally transformed into a minimization
metric. Additionally, the status type gives information on whether the run
was successful, while the additional information's most interesting entry
is the internal training loss. Furthermore, there is detailed information
on the runtime available.

As an example, let's find the best configuration evaluated. As
Auto-sklearn solves a minimization problem internally, we need to look
for the entry with the lowest loss:


.. code-block:: default


    losses_and_configurations = [
        (run_value.cost, run_key.config_id)
        for run_key, run_value in automl.automl_.runhistory_.data.items()
    ]
    losses_and_configurations.sort()
    print("Lowest loss:", losses_and_configurations[0][0])
    print(
        "Best configuration:",
        automl.automl_.runhistory_.ids_config[losses_and_configurations[0][1]]
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Lowest loss: 0.04255319148936165
    Best configuration: Configuration:
      balancing:strategy, Value: 'none'
      classifier:__choice__, Value: 'adaboost'
      classifier:adaboost:algorithm, Value: 'SAMME'
      classifier:adaboost:learning_rate, Value: 0.011233995624432622
      classifier:adaboost:max_depth, Value: 9
      classifier:adaboost:n_estimators, Value: 477
      data_preprocessing:categorical_transformer:categorical_encoding:__choice__, Value: 'no_encoding'
      data_preprocessing:categorical_transformer:category_coalescence:__choice__, Value: 'minority_coalescer'
      data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction, Value: 0.018370622484682127
      data_preprocessing:numerical_transformer:imputation:strategy, Value: 'mean'
      data_preprocessing:numerical_transformer:rescaling:__choice__, Value: 'standardize'
      feature_preprocessor:__choice__, Value: 'pca'
      feature_preprocessor:pca:keep_variance, Value: 0.6039710338898471
      feature_preprocessor:pca:whiten, Value: 'False'





Detailed statistics about the search - part 2
=============================================

To maintain compatibility with scikit-learn, Auto-sklearn gives the
same data as
`cv_results_ <https://scikit-learn.org/stable/modules/generated/sklearn.
model_selection.GridSearchCV.html>`_.


.. code-block:: default


    print(automl.cv_results_)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {'mean_test_score': array([0.91489362, 0.91489362, 0.95744681, 0.        , 0.87943262,
           0.92907801, 0.88652482]), 'mean_fit_time': array([1.12397742, 0.21181154, 0.32040238, 0.        , 0.32748747,
           0.28246903, 0.72832203]), 'params': [{'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'pca', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01, 'feature_preprocessor:pca:keep_variance': 0.9999, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'adaboost', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'pca', 'classifier:adaboost:algorithm': 'SAMME', 'classifier:adaboost:learning_rate': 1.4120696722366737, 'classifier:adaboost:max_depth': 8, 'classifier:adaboost:n_estimators': 489, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.011307840322412704, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7357867136119712, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2832469215827823, 'feature_preprocessor:pca:keep_variance': 0.99855313014133, 'feature_preprocessor:pca:whiten': 'True'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'adaboost', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'pca', 'classifier:adaboost:algorithm': 'SAMME', 'classifier:adaboost:learning_rate': 0.011233995624432622, 'classifier:adaboost:max_depth': 9, 'classifier:adaboost:n_estimators': 477, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018370622484682127, 'feature_preprocessor:pca:keep_variance': 0.6039710338898471, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'passive_aggressive', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'pca', 'classifier:passive_aggressive:C': 0.08127752986307964, 'classifier:passive_aggressive:average': 'False', 'classifier:passive_aggressive:fit_intercept': 'True', 'classifier:passive_aggressive:loss': 'hinge', 'classifier:passive_aggressive:tol': 0.0340962023335284, 'feature_preprocessor:pca:keep_variance': 0.667024556822579, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'bernoulli_nb', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'pca', 'classifier:bernoulli_nb:alpha': 0.011929966129087241, 'classifier:bernoulli_nb:fit_prior': 'True', 'feature_preprocessor:pca:keep_variance': 0.5976152033262122, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'gaussian_nb', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'pca', 'feature_preprocessor:pca:keep_variance': 0.5632675578693742, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'pca', 'classifier:gradient_boosting:early_stop': 'train', 'classifier:gradient_boosting:l2_regularization': 4.187065920024372e-09, 'classifier:gradient_boosting:learning_rate': 0.26826945251088985, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 5, 'classifier:gradient_boosting:min_samples_leaf': 20, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.720514537267965, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27686628712984507, 'feature_preprocessor:pca:keep_variance': 0.6428535788511281, 'feature_preprocessor:pca:whiten': 'True', 'classifier:gradient_boosting:n_iter_no_change': 14}], 'rank_test_scores': array([3, 3, 1, 7, 6, 2, 5]), 'status': ['Success', 'Success', 'Success', 'Crash', 'Success', 'Success', 'Success'], 'budgets': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'param_balancing:strategy': masked_array(data=['none', 'none', 'none', 'none', 'none', 'weighting',
                       'none'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U9'), 'param_classifier:__choice__': masked_array(data=['random_forest', 'adaboost', 'adaboost',
                       'passive_aggressive', 'bernoulli_nb', 'gaussian_nb',
                       'gradient_boosting'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U18'), 'param_data_preprocessing:categorical_transformer:categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'no_encoding', 'no_encoding',
                       'one_hot_encoding', 'no_encoding', 'one_hot_encoding',
                       'no_encoding'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U16'), 'param_data_preprocessing:categorical_transformer:category_coalescence:__choice__': masked_array(data=['minority_coalescer', 'minority_coalescer',
                       'minority_coalescer', 'no_coalescense',
                       'no_coalescense', 'no_coalescense', 'no_coalescense'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U18'), 'param_data_preprocessing:numerical_transformer:imputation:strategy': masked_array(data=['mean', 'mean', 'mean', 'mean', 'most_frequent',
                       'most_frequent', 'median'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U13'), 'param_data_preprocessing:numerical_transformer:rescaling:__choice__': masked_array(data=['standardize', 'robust_scaler', 'standardize',
                       'minmax', 'normalize', 'normalize', 'robust_scaler'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U13'), 'param_feature_preprocessor:__choice__': masked_array(data=['pca', 'pca', 'pca', 'pca', 'pca', 'pca', 'pca'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U3'), 'param_classifier:adaboost:algorithm': masked_array(data=[--, 'SAMME', 'SAMME', --, --, --, --],
                 mask=[ True, False, False,  True,  True,  True,  True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:adaboost:learning_rate': masked_array(data=[--, 1.4120696722366737, 0.011233995624432622, --, --,
                       --, --],
                 mask=[ True, False, False,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:adaboost:max_depth': masked_array(data=[--, 8.0, 9.0, --, --, --, --],
                 mask=[ True, False, False,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:adaboost:n_estimators': masked_array(data=[--, 489.0, 477.0, --, --, --, --],
                 mask=[ True, False, False,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:bernoulli_nb:alpha': masked_array(data=[--, --, --, --, 0.011929966129087241, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True],
           fill_value=1e+20), 'param_classifier:bernoulli_nb:fit_prior': masked_array(data=[--, --, --, --, 'True', --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:decision_tree:criterion': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:max_depth_factor': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:max_features': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:min_samples_split': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:gradient_boosting:early_stop': masked_array(data=[--, --, --, --, --, --, 'train'],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:l2_regularization': masked_array(data=[--, --, --, --, --, --, 4.187065920024372e-09],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, --, 0.26826945251088985],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:loss': masked_array(data=[--, --, --, --, --, --, 'auto'],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:max_bins': masked_array(data=[--, --, --, --, --, --, 255.0],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, --, 'None'],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, 5.0],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, 20.0],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:scoring': masked_array(data=[--, --, --, --, --, --, 'loss'],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:tol': masked_array(data=[--, --, --, --, --, --, 1e-07],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:k_nearest_neighbors:p': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:k_nearest_neighbors:weights': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:shrinkage': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:tol': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:C': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:dual': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:intercept_scaling': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:loss': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:multi_class': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:penalty': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:tol': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:C': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:gamma': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:kernel': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:max_iter': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:shrinking': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:tol': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:C': masked_array(data=[--, --, --, 0.08127752986307964, --, --, --],
                 mask=[ True,  True,  True, False,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:passive_aggressive:average': masked_array(data=[--, --, --, 'False', --, --, --],
                 mask=[ True,  True,  True, False,  True,  True,  True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:passive_aggressive:fit_intercept': masked_array(data=[--, --, --, 'True', --, --, --],
                 mask=[ True,  True,  True, False,  True,  True,  True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:passive_aggressive:loss': masked_array(data=[--, --, --, 'hinge', --, --, --],
                 mask=[ True,  True,  True, False,  True,  True,  True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:passive_aggressive:tol': masked_array(data=[--, --, --, 0.0340962023335284, --, --, --],
                 mask=[ True,  True,  True, False,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:qda:reg_param': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:random_forest:bootstrap': masked_array(data=['True', --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value='N/A',
                dtype='<U4'), 'param_classifier:random_forest:criterion': masked_array(data=['gini', --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value='N/A',
                dtype='<U4'), 'param_classifier:random_forest:max_depth': masked_array(data=['None', --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value='N/A',
                dtype='<U4'), 'param_classifier:random_forest:max_features': masked_array(data=[0.5, --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:random_forest:max_leaf_nodes': masked_array(data=['None', --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value='N/A',
                dtype='<U4'), 'param_classifier:random_forest:min_impurity_decrease': masked_array(data=[0.0, --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:random_forest:min_samples_leaf': masked_array(data=[1.0, --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:random_forest:min_samples_split': masked_array(data=[2.0, --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, --, --, --, --, --, --],
                 mask=[False,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20), 'param_classifier:sgd:alpha': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:average': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:learning_rate': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:loss': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:penalty': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:tol': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': masked_array(data=[0.01, 0.011307840322412704, 0.018370622484682127, --,
                       --, --, --],
                 mask=[False, False, False,  True,  True,  True,  True],
           fill_value=1e+20), 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': masked_array(data=[--, 0.7357867136119712, --, --, --, --,
                       0.720514537267965],
                 mask=[ True, False,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': masked_array(data=[--, 0.2832469215827823, --, --, --, --,
                       0.27686628712984507],
                 mask=[ True, False,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_feature_preprocessor:pca:keep_variance': masked_array(data=[0.9999, 0.99855313014133, 0.6039710338898471,
                       0.667024556822579, 0.5976152033262122,
                       0.5632675578693742, 0.6428535788511281],
                 mask=[False, False, False, False, False, False, False],
           fill_value=1e+20), 'param_feature_preprocessor:pca:whiten': masked_array(data=['False', 'True', 'False', 'False', 'False', 'False',
                       'True'],
                 mask=[False, False, False, False, False, False, False],
           fill_value='N/A',
                dtype='<U5'), 'param_classifier:gradient_boosting:n_iter_no_change': masked_array(data=[--, --, --, --, --, --, 14.0],
                 mask=[ True,  True,  True,  True,  True,  True, False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:validation_fraction': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:shrinkage_factor': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:coef0': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:degree': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:epsilon': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:eta0': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:l1_ratio': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:power_t': masked_array(data=[--, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True],
           fill_value=1e+20,
                dtype=float64)}




Inspect the components of the best model
========================================

Iterate over the components of the model and print
The explained variance ratio per stage


.. code-block:: default

    for i, (weight, pipeline) in enumerate(automl.get_models_with_weights()):
        for stage_name, component in pipeline.named_steps.items():
            if 'preprocessor' in stage_name:
                print(
                    "The {}th pipeline has a explained variance of {}".format(
                        i,
                        # The component is an instance of AutoSklearnChoice.
                        # Access the sklearn object via the choice attribute
                        # We want the explained variance attributed of
                        # each principal component
                        component.choice.preprocessor.explained_variance_ratio_
                    )
                )




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    The 0th pipeline has a explained variance of [0.43295688 0.1790573 ]
    The 1th pipeline has a explained variance of [4.32956881e-01 1.79057296e-01 1.11737571e-01 6.80724345e-02
     5.94611519e-02 3.70629898e-02 2.38430977e-02 1.49326086e-02
     1.37641366e-02 1.13704890e-02 1.03737258e-02 8.74116751e-03
     7.57629717e-03 4.86528503e-03 3.32225143e-03 2.55773043e-03
     2.20759805e-03 1.88675402e-03 1.36245140e-03 1.03409213e-03
     8.39749085e-04 7.91287172e-04 6.75655689e-04 5.42961621e-04
     5.02641737e-04 2.07827509e-04 1.74597367e-04]
    The 2th pipeline has a explained variance of [6.86302645e-01 1.25544258e-01 9.02100053e-02 6.19996042e-02
     1.45735150e-02 6.43944771e-03 4.53221101e-03 3.18708698e-03
     1.95256209e-03 1.57315864e-03 1.32456937e-03 7.57120105e-04
     4.44789943e-04]
    The 3th pipeline has a explained variance of [0.76699224]
    The 4th pipeline has a explained variance of [0.76699224]
    The 5th pipeline has a explained variance of [0.69475704]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  24.796 seconds)


.. _sphx_glr_download_examples_40_advanced_example_get_pipeline_components.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_get_pipeline_components.py <example_get_pipeline_components.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_get_pipeline_components.ipynb <example_get_pipeline_components.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
