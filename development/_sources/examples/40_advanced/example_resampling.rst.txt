.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_resampling.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_examples_40_advanced_example_resampling.py:


=====================
Resampling Strategies
=====================

In *auto-sklearn* it is possible to use different resampling strategies
by specifying the arguments ``resampling_strategy`` and
``resampling_strategy_arguments``. The following example shows common
settings for the ``AutoSklearnClassifier``.


.. code-block:: default


    import numpy as np
    import sklearn.model_selection
    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.classification









Data Loading
============


.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








Holdout
=======


.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_resampling_example_tmp',
        output_folder='/tmp/autosklearn_resampling_example_out',
        disable_evaluator_output=False,
        # 'holdout' with 'train_size'=0.67 is the default argument setting
        # for AutoSklearnClassifier. It is explicitly specified in this example
        # for demonstrational purpose.
        resampling_strategy='holdout',
        resampling_strategy_arguments={'train_size': 0.67},
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(dask_client=None,
                          delete_output_folder_after_terminate=True,
                          delete_tmp_folder_after_terminate=True,
                          disable_evaluator_output=False,
                          ensemble_memory_limit=1024, ensemble_nbest=50,
                          ensemble_size=50, exclude_estimators=None,
                          exclude_preprocessors=None, get_smac_object_callback=None,
                          include_estimators=None, include_preprocessors=None,
                          initi...
                          logging_config=None, max_models_on_disc=50,
                          metadata_directory=None, metric=None,
                          ml_memory_limit=3072, n_jobs=None,
                          output_folder='/tmp/autosklearn_resampling_example_out',
                          per_run_time_limit=30, resampling_strategy='holdout',
                          resampling_strategy_arguments={'train_size': 0.67},
                          seed=1, smac_scenario_args=None,
                          time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_resampling_example_tmp')



Get the Score of the final ensemble
===================================


.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score holdout: ", sklearn.metrics.accuracy_score(y_test, predictions))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score holdout:  0.9440559440559441




Cross-validation
================


.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_resampling_example_tmp',
        output_folder='/tmp/autosklearn_resampling_example_out',
        disable_evaluator_output=False,
        resampling_strategy='cv',
        resampling_strategy_arguments={'folds': 5},
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')

    # One can use models trained during cross-validation directly to predict
    # for unseen data. For this, all k models trained during k-fold
    # cross-validation are considered as a single soft-voting ensemble inside
    # the ensemble constructed with ensemble selection.
    print('Before re-fit')
    predictions = automl.predict(X_test)
    print("Accuracy score CV", sklearn.metrics.accuracy_score(y_test, predictions))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Before re-fit
    Accuracy score CV 0.951048951048951




Perform a refit
===============
During fit(), models are fit on individual cross-validation folds. To use
all available data, we call refit() which trains all models in the
final ensemble on the whole dataset.


.. code-block:: default

    print('After re-fit')
    automl.refit(X_train.copy(), y_train.copy())
    predictions = automl.predict(X_test)
    print("Accuracy score CV", sklearn.metrics.accuracy_score(y_test, predictions))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    After re-fit
    Accuracy score CV 0.951048951048951




scikit-learn splitter objects
=============================
It is also possible to use
`scikit-learn's splitter classes <https://scikit-learn.org/stable/modules/classes.html#splitter
-classes>`_ to further customize the outputs. In case one needs to have 100% control over the
splitting, it is possible to use
`scikit-learn's PredefinedSplit <https://scikit-learn.org/stable/modules/generated/
sklearn.model_selection.PredefinedSplit.html>`_.

Below is an example of using a predefined split. We split the training
data by the first feature. In practice, one would use a splitting according
to the use case at hand.


.. code-block:: default


    resampling_strategy = sklearn.model_selection.PredefinedSplit
    resampling_strategy_arguments = {'test_fold': np.where(X_train[:, 0] < np.mean(X_train[:, 0]))[0]}

    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_resampling_example_tmp',
        output_folder='/tmp/autosklearn_resampling_example_out',
        disable_evaluator_output=False,
        resampling_strategy=resampling_strategy,
        resampling_strategy_arguments=resampling_strategy_arguments,
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(dask_client=None,
                          delete_output_folder_after_terminate=True,
                          delete_tmp_folder_after_terminate=True,
                          disable_evaluator_output=False,
                          ensemble_memory_limit=1024, ensemble_nbest=50,
                          ensemble_size=50, exclude_estimators=None,
                          exclude_preprocessors=None, get_smac_object_callback=None,
                          include_estimators=None, include_preprocessors=None,
                          initi...
           325, 326, 327, 329, 332, 333, 334, 335, 337, 338, 339, 343, 345,
           348, 349, 350, 351, 354, 355, 356, 357, 358, 361, 363, 364, 365,
           366, 367, 370, 371, 372, 373, 374, 377, 378, 380, 381, 383, 384,
           385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 398, 400, 401,
           402, 403, 407, 409, 410, 411, 414, 416, 417, 418, 419, 422, 424,
           425])},
                          seed=1, smac_scenario_args=None,
                          time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_resampling_example_tmp')



For custom resampling strategies (i.e. resampling strategies that are not
defined as strings by Auto-sklearn) it is necessary to perform a refit:


.. code-block:: default

    automl.refit(X_train, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(dask_client=None,
                          delete_output_folder_after_terminate=True,
                          delete_tmp_folder_after_terminate=True,
                          disable_evaluator_output=False,
                          ensemble_memory_limit=1024, ensemble_nbest=50,
                          ensemble_size=50, exclude_estimators=None,
                          exclude_preprocessors=None, get_smac_object_callback=None,
                          include_estimators=None, include_preprocessors=None,
                          initi...
           325, 326, 327, 329, 332, 333, 334, 335, 337, 338, 339, 343, 345,
           348, 349, 350, 351, 354, 355, 356, 357, 358, 361, 363, 364, 365,
           366, 367, 370, 371, 372, 373, 374, 377, 378, 380, 381, 383, 384,
           385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 398, 400, 401,
           402, 403, 407, 409, 410, 411, 414, 416, 417, 418, 419, 422, 424,
           425])},
                          seed=1, smac_scenario_args=None,
                          time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_resampling_example_tmp')



Get the Score of the final ensemble (again)
===========================================

Obviously, this score is pretty bad as we "destroyed" the dataset by
splitting it on the first feature.


.. code-block:: default

    predictions = automl.predict(X_test)
    print("Accuracy score custom split", sklearn.metrics.accuracy_score(y_test, predictions))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score custom split 0.38461538461538464





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  46.365 seconds)


.. _sphx_glr_download_examples_40_advanced_example_resampling.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_resampling.py <example_resampling.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_resampling.ipynb <example_resampling.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
