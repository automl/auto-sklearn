
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_interpretable_models.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_interpretable_models.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_interpretable_models.py:


====================
Interpretable models
====================

The following example shows how to inspect the models which *auto-sklearn*
optimizes over and how to restrict them to an interpretable subset.

.. GENERATED FROM PYTHON SOURCE LINES 10-14

.. code-block:: default

    import autosklearn.classification
    import sklearn.datasets
    import sklearn.metrics








.. GENERATED FROM PYTHON SOURCE LINES 15-21

Show available classification models
====================================

We will first list all classifiers Auto-sklearn chooses from. A similar
call is available for preprocessors (see below) and regression (not shown)
as well.

.. GENERATED FROM PYTHON SOURCE LINES 21-26

.. code-block:: default

    from autosklearn.pipeline.components.classification import ClassifierChoice

    for name in ClassifierChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    adaboost
    bernoulli_nb
    decision_tree
    extra_trees
    gaussian_nb
    gradient_boosting
    k_nearest_neighbors
    lda
    liblinear_svc
    libsvm_svc
    mlp
    multinomial_nb
    passive_aggressive
    qda
    random_forest
    sgd




.. GENERATED FROM PYTHON SOURCE LINES 27-29

Show available preprocessors
============================

.. GENERATED FROM PYTHON SOURCE LINES 29-35

.. code-block:: default


    from autosklearn.pipeline.components.feature_preprocessing import FeaturePreprocessorChoice

    for name in FeaturePreprocessorChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    densifier
    extra_trees_preproc_for_classification
    extra_trees_preproc_for_regression
    fast_ica
    feature_agglomeration
    kernel_pca
    kitchen_sinks
    liblinear_svc_preprocessor
    no_preprocessing
    nystroem_sampler
    pca
    polynomial
    random_trees_embedding
    select_percentile_classification
    select_percentile_regression
    select_rates_classification
    select_rates_regression
    truncatedSVD




.. GENERATED FROM PYTHON SOURCE LINES 36-38

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 38-43

.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








.. GENERATED FROM PYTHON SOURCE LINES 44-52

Build and fit a classifier
==========================

We will now only use a subset of the given classifiers and preprocessors.
Furthermore, we will restrict the ensemble size to ``1`` to only use the
single best model in the end. However, we would like to note that the
choice of which models is deemed interpretable is very much up to the user
and can change from use case to use case.

.. GENERATED FROM PYTHON SOURCE LINES 52-69

.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp',
        include={
            'classifier': [
                'decision_tree', 'lda', 'sgd'
            ],
            'feature_preprocessor': [
                'no_preprocessing', 'polynomial', 'select_percentile_classification'
            ]
        },
        ensemble_size=1,
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(ensemble_size=1,
                          include={'classifier': ['decision_tree', 'lda', 'sgd'],
                                   'feature_preprocessor': ['no_preprocessing',
                                                            'polynomial',
                                                            'select_percentile_classification']},
                          per_run_time_limit=30, time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp')



.. GENERATED FROM PYTHON SOURCE LINES 70-72

Print the final ensemble constructed by auto-sklearn
====================================================

.. GENERATED FROM PYTHON SOURCE LINES 72-75

.. code-block:: default


    print(automl.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'sgd', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:sgd:alpha': 0.0003194044719261622, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'invscaling', 'classifier:sgd:loss': 'log', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 3.224657440425691e-05, 'data_preprocessor:feature_type:categorical_transformer:categorical_encoding:__choice__': 'encoding', 'data_preprocessor:feature_type:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'False', 'feature_preprocessor:polynomial:interaction_only': 'True', 'classifier:sgd:eta0': 0.005855617194547085, 'classifier:sgd:power_t': 0.5, 'data_preprocessor:feature_type:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.36245512200942104},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    ]




.. GENERATED FROM PYTHON SOURCE LINES 76-78

Get the Score of the final ensemble
===================================

.. GENERATED FROM PYTHON SOURCE LINES 78-81

.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:", sklearn.metrics.accuracy_score(y_test, predictions))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score: 0.951048951048951





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  2.315 seconds)


.. _sphx_glr_download_examples_40_advanced_example_interpretable_models.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/40_advanced/example_interpretable_models.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_interpretable_models.py <example_interpretable_models.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_interpretable_models.ipynb <example_interpretable_models.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
